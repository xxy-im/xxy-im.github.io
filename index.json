[{"categories":["深度学习"],"content":"GAN，越来越有意思了 ","date":"2022-06-01","objectID":"/pix2pix/:0:0","series":null,"tags":["机器学习","深度学习","论文复现","GAN"],"title":"[论文复现] pix2pix","uri":"/pix2pix/#"},{"categories":["深度学习"],"content":"Image-to-Image Translation with Condition Adversarial Networks 论文下载（CVPR） 论文下载（arxiv，更详细） ","date":"2022-06-01","objectID":"/pix2pix/:0:0","series":null,"tags":["机器学习","深度学习","论文复现","GAN"],"title":"[论文复现] pix2pix","uri":"/pix2pix/#image-to-image-translation-with-condition-adversarial-networks"},{"categories":["深度学习"],"content":"概述 论文开篇直接放了张图片告诉你这个网络可以做哪些图片到图片的翻译任务。这些任务包括但不限于语义标签图到生成图，物体边缘轮廓图到构建出的实体图，图片上色等。论文将这些任务同一称为像素到像素的映射（map pix to pix）。这篇论文的团队又是一个良心团队，不仅给了代码，还有示例网站，还给了colab页面以及网友们自己做的艺术创作。都在这里 https://phillipi.github.io/pix2pix/ 所有这些图片翻译任务都只需要用同一个网络结构，喂不同的数据就可以实现。这就是它牛逼的地方，直接给了一个通用解决方案。 因为需要输入一张图片，可以把这个输入的图片作为条件，所以这个GAN模型是有条件的（conditional GAN）。 论文提到了一个叫 “structure loss” 的东西，说以前的图片翻译问题通常会将输出空间认为是无结构化（”unstructured“），像素和像素之间是条件独立的（与周围的像素无关，只跟输入图片中对应的像素有关）。而cGAN就能学到一个 “structure loss” ，对输出图片中相邻的像素进行惩罚。 cGAN就是在GAN的基础上加了一个条件向量。生成图片的时候在噪声后面接个条件向量，判别的时候图片也是和这个条件向量一起判别，这个条件向量在MNIST数据集上可以代表数字，CIFAR数据集上可以代表类别，总之按你给定的条件生成相应的图像。理解了GAN的话很容易就能写出cGAN的代码，所以就没写cGAN的复现。 ","date":"2022-06-01","objectID":"/pix2pix/:1:0","series":null,"tags":["机器学习","深度学习","论文复现","GAN"],"title":"[论文复现] pix2pix","uri":"/pix2pix/#概述"},{"categories":["深度学习"],"content":"模型及训练 模型大体的框架是用的和DCGAN类似的结构，生成器和判别器都是 convolution-BatchNorm-ReLU 这样的 CBR 结构。但不同的是，推理过程是用测试集的统计数据进行batch normalization，当batch size为1时又叫做 “instance normalization”，这是图像生成任务常用的方法。参考这篇论文《Instance normalization: The missing ingredient for fast stylization》 生成器： 用的是U-Net那样的一个U型卷积结构，是图像分割领域的经典论文，至今仍活跃于医学图像领域。 过去大部分做 Image-to-Image 任务的GAN的生成器都是通过对输入先下采样再上采样的方式生成图像（encoder-decoder结构）。但是这样会导致在下采样通过瓶颈层时丢失掉很多特征，而我们的任务需要输出图像与输入图像的一些底层特征的相同的，如轮廓和边缘。而 U-Net 结构就很好的解决了这个问题，用类似 ResNet 那样的方法把通过瓶颈层前的特征直接送到对称的上采样层上，这样就保留了图像的底层特征 。 判别器： 论文给取了个名字叫马尔可夫判别器，又叫 PatchGAN 分类器，这个判别器将图片分成很多小块（Patch）分别判别真假概率（Patch之间相互独立）。这样判别器的输出就不再是一个数值了，图片为真的概率为判别器输出结果平均的平均值。这么做的一个目的是为了方便捕捉图片的高频信息（纹理，边缘，风格等）。论文在 Cityscapes 数据集上做的 label→photo 实验，Patch为 70x70 得出的效果最好。 这样的判别器将一张图片视为一个马尔可夫随机场，如果像素之间的距离超过了一个Patch的直径就认为它们是独立无关的。 低频就是颜色缓慢变化，也就是灰度缓慢地变化，代表着那是连续渐变的一块区域； 高频就是频率变化快，相邻区域之间灰度相差很大。 具体代码实现的时候并不是真的把图片分成 NxN 块后再判别，而是通过改变卷积操作的感受野来实现 目标函数： 除了GAN原本的目标函数，还需要一个函数评估生成图与真实图的“距离”（像素之间的差异），论文用的 L1 距离，选用L1是因为这些距离函数作用在像素层面上会激励图像模糊化，而L1距离相较L2来说图像的模糊程度会更少。（不会捕捉高频信息，但能捕捉到低频信息，高频信息已经丢给判别器去捕捉了） $$ \\mathcal{L}_ {L 1}(G)=\\mathbb{E}_{x, y, z}\\left[|y-G(x, z)|_{1}\\right] $$ 加在原目标函数后，最终目标函数为 $$ G^{*}=\\arg \\min _{G} \\max _{D} \\mathcal{L} _{c G A N}(G, D)+\\lambda \\mathcal{L} _{L 1}(G) $$ 和传统cGAN还有个不同的就是，pix2pix把噪声采样 $z$ 给拿掉了，因为生成器很容易会忽略噪声输入。论文最终通过使用dropout来引入随机性，不单是训练过程用的dropout，推理过程也用dropout。但也提到了，这种方法带来的随机性也不是很大。 所以论文说如何使cGAN产生高随机性也是个重要的工作。 ","date":"2022-06-01","objectID":"/pix2pix/:2:0","series":null,"tags":["机器学习","深度学习","论文复现","GAN"],"title":"[论文复现] pix2pix","uri":"/pix2pix/#模型及训练"},{"categories":["深度学习"],"content":"评价指标 在Improved GAN 中提到过一个叫做 Inception Score 的评价指标。这篇论文里又提出了一个 FCN-score 用于语义标签转图片这个任务上评估图像生成质量。 用一个现成的FCN模型给生成图做语义分割得到的label和真实的label做比较，这时就可以用语义分割领域现有的评价指标，如 per-pixel accuracy，per-class accuracy 和 Class IOU。 ","date":"2022-06-01","objectID":"/pix2pix/:3:0","series":null,"tags":["机器学习","深度学习","论文复现","GAN"],"title":"[论文复现] pix2pix","uri":"/pix2pix/#评价指标"},{"categories":["深度学习"],"content":"核心代码 生成器： class UNetBlock(nn.Module): def __init__(self, in_channel, out_channel, normalize=True, down=True, activation=None, dropout=False): super().__init__() # 参数 4, 2, 1，在下采样是宽高缩小两倍，上采样时扩大两倍 self.net = nn.Sequential( nn.Conv2d(in_channel, out_channel, 4, 2, 1, bias=False if normalize else True) if down else nn.ConvTranspose2d(in_channel, out_channel, 4, 2, 1, bias=False if normalize else True), ) if normalize: self.net.append(nn.BatchNorm2d(out_channel)) self.net.append(nn.LeakyReLU(0.2, True) if activation is None else activation) if dropout: self.net.append(nn.Dropout(0.5)) def forward(self, x): return self.net(x) class UNetGenerator(nn.Module): def __init__(self, in_channels=3, init_weights=True): super().__init__() conv_channels = [64, 128, 256, 512, 512, 512, 512, 512, 512] self.down1 = UNetBlock(in_channels, conv_channels[0], down=True) self.down2 = UNetBlock(conv_channels[0], conv_channels[1], down=True) self.down3 = UNetBlock(conv_channels[1], conv_channels[2], down=True) self.down4 = UNetBlock(conv_channels[2], conv_channels[3], down=True) self.down5 = UNetBlock(conv_channels[3], conv_channels[4], down=True) self.down6 = UNetBlock(conv_channels[4], conv_channels[5], down=True) self.down7 = UNetBlock(conv_channels[5], conv_channels[6], down=True) self.bottleneck = UNetBlock(conv_channels[6], conv_channels[7], down=True) self.up1 = UNetBlock(conv_channels[7], conv_channels[6], down=False, activation=nn.ReLU(True)) self.up2 = UNetBlock(conv_channels[6] * 2, conv_channels[5], down=False, activation=nn.ReLU(True), dropout=True) self.up3 = UNetBlock(conv_channels[5] * 2, conv_channels[4], down=False, activation=nn.ReLU(True)) self.up4 = UNetBlock(conv_channels[4] * 2, conv_channels[3], down=False, activation=nn.ReLU(True), dropout=True) self.up5 = UNetBlock(conv_channels[3] * 2, conv_channels[2], down=False, activation=nn.ReLU(True)) self.up6 = UNetBlock(conv_channels[2] * 2, conv_channels[1], down=False, activation=nn.ReLU(True), dropout=True) self.up7 = UNetBlock(conv_channels[1] * 2, conv_channels[0], down=False, activation=nn.ReLU(True)) self.out = UNetBlock(conv_channels[0] * 2, in_channels, normalize=False, down=False, activation=nn.Tanh()) if init_weights: for m in self.modules(): if isinstance(m, nn.Conv2d): nn.init.normal_(m.weight, mean=0, std=0.02) if isinstance(m, nn.BatchNorm2d): nn.init.normal_(m.weight, mean=1, std=0.02) if m.bias is not None: nn.init.constant_(m.bias, 0) def forward(self, x): d1 = self.down1(x) # 假设x.shape = (N, 3, 512, 512), d1.shape = （N, 64, 256, 256) d2 = self.down2(d1) # (N, 128, 128, 128) d3 = self.down3(d2) # (N, 256, 64, 64) d4 = self.down4(d3) # (N, 512, 32, 32) d5 = self.down5(d4) # (N, 512, 16, 16) d6 = self.down6(d5) # (N, 512, 8, 8) d7 = self.down7(d6) # (N, 512, 4, 4) bottleneck = self.bottleneck(d7) # (N, 512, 2, 2) u1 = self.up1(bottleneck) # (N, 512, 4, 4) u2 = self.up2(torch.cat((u1, d7), 1)) # (N, 512, 8, 8) u3 = self.up3(torch.cat((u2, d6), 1)) # (N, 512, 16, 16) u4 = self.up4(torch.cat((u3, d5), 1)) # (N, 512, 32, 32) u5 = self.up5(torch.cat((u4, d4), 1)) # (N, 256, 64, 64) u6 = self.up6(torch.cat((u5, d3), 1)) # (N, 128, 128, 128) u7 = self.up7(torch.cat((u6, d2), 1)) # (N, 64, 256, 256) return self.out(torch.cat((u7, d1), 1)) # (N, 3, 512, 512) 判别器：（和DCGAN的判别器挺像的） # 默认 70x70 的感受野（patch） class PatchDiscriminator(nn.Module): def __init__(self, in_channels=6, init_weights=True): super().__init__() conv_channels = [64, 128, 256, 512] def cbr_block(in_channel, out_channel, normalize=True, kernel_size=4, stride=2, padding=1, activation=None): layers = [ nn.Conv2d( in_channel, out_channel, kernel_size=kernel_size, stride=stride, padding=padding, bias=False if normalize else True), ] if normalize: layers.append(nn.BatchNorm2d(out_channel)) layers.append(nn.LeakyReLU(0.2, inplace=True) if activation is None else activation) return layers # 感受野计算公式为 (output_size - 1) * stride + ksize # 倒着往上推就能算出感受野为70，最后一个output_size按1算 self.net = nn.Sequential( *cbr_block(in_channels, conv_","date":"2022-06-01","objectID":"/pix2pix/:4:0","series":null,"tags":["机器学习","深度学习","论文复现","GAN"],"title":"[论文复现] pix2pix","uri":"/pix2pix/#核心代码"},{"categories":["深度学习"],"content":"效果 我用的漫画人物草图上色数据集。图片有点大，最近因为网的问题没显卡跑，所以拖了这么久才更新（其实是因为懒）。 数据集我放网盘了 链接：https://pan.baidu.com/s/1vtAp96HaPBLEE6NVUljfHA?pwd=0bjz 提取码：0bjz 随便跑了几十个epoch，感觉效果不是很好呀，是我哪里写错了吗，可能加上关于色彩亮度的数据增强会好点吧 ","date":"2022-06-01","objectID":"/pix2pix/:5:0","series":null,"tags":["机器学习","深度学习","论文复现","GAN"],"title":"[论文复现] pix2pix","uri":"/pix2pix/#效果"},{"categories":["深度学习"],"content":"总结 这东西就很牛，你能想到的Image to Image任务几乎都能用这个来做，虚拟主播都能用这东西做。arxiv上的论文比正式投稿的论文上多很多示例（因为投稿限制了页数）。 完整代码 https://github.com/xxy-im/Just4GAN/tree/main/models/pix2pix 如果会web的同学也可以做一个很好玩的网站出来。（反正我不会） 不能再懒下去了 ","date":"2022-06-01","objectID":"/pix2pix/:6:0","series":null,"tags":["机器学习","深度学习","论文复现","GAN"],"title":"[论文复现] pix2pix","uri":"/pix2pix/#总结"},{"categories":["深度学习"],"content":"还以为终于能GAN倒CIFAR10了 ","date":"2022-05-14","objectID":"/improvedgan/:0:0","series":null,"tags":["机器学习","深度学习","论文复现","GAN"],"title":"[论文阅读] Improved GAN","uri":"/improvedgan/#"},{"categories":["深度学习"],"content":"Improved Techniques for Training GANs 论文下载地址： https://arxiv.org/pdf/1606.03498v1.pdf ","date":"2022-05-14","objectID":"/improvedgan/:0:0","series":null,"tags":["机器学习","深度学习","论文复现","GAN"],"title":"[论文阅读] Improved GAN","uri":"/improvedgan/#improved-techniques-for-training-gans"},{"categories":["深度学习"],"content":"基本概览 写完DCGAN的时候我说再也不用CIFAR10训练GAN了，但是这篇论文开篇就告诉我他们用这些新方法训练GAN在CIFAR10上取得了很好的效果。看到这里的时候我还以为我要跟CIFAR10要死磕到底了。 GAN它爹 Ian Goodfellow 也在这篇论文的团队里。在第一篇GAN论文中提到过理想状态下是GAN的对抗过程达到一个纳什均衡，但通常用梯度下降方法训练出来的模型是使得损失函数的loss更小，而不是达到纳什均衡。Ian的另外一篇论文On distinguishability criteria for estimating generative models(https://arxiv.org/pdf/1412.6515.pdf)也提到过，当试图达到纳什均衡时，算法无法收敛。 于是这篇论文提出了一些用于GAN的新的结构特征和训练过程，提升了半监督学习的性能以及样本生成质量。这些新技术产生的动机是由非收敛问题的一个启发式理解（heuristic understanding）。 GAN训练的过程中，生成器和判别器都希望能最小化自己的损失函数，这样就会存在一个问题。在第一篇GAN复现中提到过，GAN的目标函数是 $$ \\min_{G}\\max_{D}V(D, G)=\\mathbb{E}_{\\boldsymbol{x}\\sim p_{\\text {data }}(\\boldsymbol{x})}[\\log{D}(\\boldsymbol{x})]+\\mathbb{E}_{\\boldsymbol{z}\\sim p_{\\boldsymbol{z}}(\\boldsymbol{z})}[\\log (1-D(G(\\boldsymbol{z})))] $$ 可以看到，对于传统的GAN训练，生成器和判别器都希望最小化它们各自的损失函数。用$J^{(D)}=(\\theta^{D},\\theta^{G})$ 表示判别器损失函数，$J^{(G)}=(\\theta^{D},\\theta^{G})$ 表示生成器损失函数，其中 $\\theta^{(D)}$ 和 $\\theta^{(G)}$ 分别为判别器和生成器模型的权重。当修改 $\\theta^{(D)}$以减小 $J^{(D)}$时会导致 $J^{(G)}$增长，同样修改 $\\theta^{(G)}$减少 $J^{(G)}$会导致 $J^{(D)}$增长。因此梯度下降法很难使得GAN收敛到纳什均衡的状态。 论文举了个栗子，有两个模型，一个需要最小化 $xy$，另一个要最小化 $-xy$。使用梯度下降法虽然可以收敛到一个平稳的点，但是无法收敛到 (0, 0)，这个是应该是 Ian 的花书里提到的栗子 大佬就是这样，引用全是自己的论文和书 。 下面就是论文提出的有助于收敛的一些技术 ","date":"2022-05-14","objectID":"/improvedgan/:1:0","series":null,"tags":["机器学习","深度学习","论文复现","GAN"],"title":"[论文阅读] Improved GAN","uri":"/improvedgan/#基本概览"},{"categories":["深度学习"],"content":"Improved Techniques for GAN ","date":"2022-05-14","objectID":"/improvedgan/:2:0","series":null,"tags":["机器学习","深度学习","论文复现","GAN"],"title":"[论文阅读] Improved GAN","uri":"/improvedgan/#improved-techniques-for-gan"},{"categories":["深度学习"],"content":"特征匹配（Feature matching） 换掉了生成器的目标函数，不再是最大化判别器的输出了 （$\\max(logD(G(z)))$）。新的目标是当经过判别器的中间层时，真实数据 $x$ 与生成数据 $G(z)$ 的中间层特征尽可能相似。即 $|f(x)-f(G(z))|$ 要尽可能小，$f$ 为判别器中间层输出的 feature map 完整的目标函数定义如下： $$ \\left|\\mathbb{E}_ {\\boldsymbol{x} \\sim p_{\\text {data }}} \\mathbf{f}(\\boldsymbol{x})-\\mathbb{E}_{\\boldsymbol{z} \\sim p_{\\boldsymbol{z}}(\\boldsymbol{z})} \\mathbf{f}(G(\\boldsymbol{z}))\\right|_{2}^{2} $$ 这种方法相比用概率去拟合分布能更好的收敛吧，以前认为判别器输出为真的概率越大生成的数据与训练数据的分布更加拟合，而现在通过比较生成数据与真实数据通过判别器时中间输出的特征来达到拟合效果。 给我的直观感觉就是向着那个“黑盒”里面走了一步。 ","date":"2022-05-14","objectID":"/improvedgan/:2:1","series":null,"tags":["机器学习","深度学习","论文复现","GAN"],"title":"[论文阅读] Improved GAN","uri":"/improvedgan/#特征匹配feature-matching"},{"categories":["深度学习"],"content":"小批量判别器 （Minibatch discriminator） 复现GAN的时候提到过GAN不容易训练的一个原因是会出现模型坍塌（Mode collapse），但是生成器总是生成同样的东西。避免这个问题的一个方法就是让判别器每次“看”一批图片 （在复现DCGAN的时候我把batch size调大了原来就是这个道理吗）。不过现在训练模型应该已经没有一张张图片训练的吧。不过他这里的minibatch操作不只是简单的读批量图片，还有一系列的计算，有点复杂。 $f(x_i) \\in \\mathbb{R}^{A}$ 为判别器某一层的输入向量 $x_i$ 对应的输出，然后乘上一个张量 $\\dot{T} \\in \\mathbb{R}^{A \\times B \\times C}$ 得到矩阵 $M_i$ 。 批量大小为 $B$ 的输入得到 $M_i \\dots M_B$，然后对不同矩阵的同一行计算 $L_1$距离再计算$exp$。令 $c_{b}\\left(\\boldsymbol{x}_{i}, \\boldsymbol{x}_{j}\\right)=\\exp(-||M_{i,b}-M_{j,b}||_{L_1})$ 则， $$ o\\left(\\boldsymbol{x}_ {i}\\right)_{b}=\\sum_{j=1}^{n} c_{b}\\left(\\boldsymbol{x}_{i}, \\boldsymbol{x}_{j}\\right) \\in \\mathbb{R} $$ $$ o\\left(\\boldsymbol{x}_ {i}\\right)=\\left[o\\left(\\boldsymbol{x}_{i}\\right)_{1}, o\\left(\\boldsymbol{x}_{i}\\right)_{2}, \\ldots, o\\left(\\boldsymbol{x}_{i}\\right)_{B}\\right] \\in \\mathbb{R}^{B} $$ $$ o(\\mathbf{X}) \\in \\mathbb{R}^{n \\times B} $$ 最后还要讲 minibatch层的输出 $o\\left(\\boldsymbol{x}_{i}\\right)$ 与 $f(x_i)$ 串联后再输入到下一层，感觉好复杂啊。 论文中还提到，Minibatch discrimination可以让GAN很快的生成较好的图片，而Feature matching更适合用于半监督学习的分类任务。 ","date":"2022-05-14","objectID":"/improvedgan/:3:0","series":null,"tags":["机器学习","深度学习","论文复现","GAN"],"title":"[论文阅读] Improved GAN","uri":"/improvedgan/#小批量判别器-minibatch-discriminator"},{"categories":["深度学习"],"content":"历史参数平均（Historical averaging） 在生成器和判别器的损失函数中加一项 $$ \\left|\\boldsymbol{\\theta}-\\frac{1}{t} \\sum_{i=1}^{t} \\boldsymbol{\\theta}[i]\\right|^{2} $$ 其中 $\\boldsymbol{\\theta}[i]$ 表示第 $i$ 时刻的两个模型的参数。这个方式使得模型更能想平衡点靠拢。 ","date":"2022-05-14","objectID":"/improvedgan/:3:1","series":null,"tags":["机器学习","深度学习","论文复现","GAN"],"title":"[论文阅读] Improved GAN","uri":"/improvedgan/#历史参数平均historical-averaging"},{"categories":["深度学习"],"content":"单边标签平滑（One-sided label smoothing） 如果用 $\\alpha$ 代替真实样本的标签 1，用 $\\beta$ 代替标签 0，就能得到一个更好的判别器 $$ D(\\boldsymbol{x})=\\frac{\\alpha p_{\\text {data }}(\\boldsymbol{x})+\\beta p_{\\text {model }}(\\boldsymbol{x})}{p_{\\text {data }}(\\boldsymbol{x})+p_{\\text {model }}(\\boldsymbol{x})} $$ 这公式的原公式在GAN论文中也有说明 为防止 $p_{data}(x)$ 接近 0 而 $p_{model}(x)$ 很大导致无法向真实数据拟合，只用 $\\alpha$ 替换 1，负样本的 0 标签保持不变。因此叫做单边smooth。 ","date":"2022-05-14","objectID":"/improvedgan/:3:2","series":null,"tags":["机器学习","深度学习","论文复现","GAN"],"title":"[论文阅读] Improved GAN","uri":"/improvedgan/#单边标签平滑one-sided-label-smoothing"},{"categories":["深度学习"],"content":"虚拟批量归一化（Virtual Batch Normalization） BN层虽然很有用，但是也会使得神经网络对于一个输入 $x$ 的输出高度依赖于同一批次中的其他一些输入 $x^\\prime$ 。因此论文提出了一个虚拟批量归一化方法（VBN），在这个过程中，每个输入 $x$ 的归一化都基于一些输入的作为参考批量（reference batch）收集来的统计数据以及 $x$ 本身， 这些输入在训练的一开始就选择好并且固定了。参考批量仅使用其自身的统计数据进行规范化处理 VBN的计算代价很大，因为它需要在两个小批量数据上运行前向传播，所以我们只在生成器网络中使用它。 ","date":"2022-05-14","objectID":"/improvedgan/:3:3","series":null,"tags":["机器学习","深度学习","论文复现","GAN"],"title":"[论文阅读] Improved GAN","uri":"/improvedgan/#虚拟批量归一化virtual-batch-normalization"},{"categories":["深度学习"],"content":"图片质量评估 之前复现DCGAN的时候也提到了，不是epoch越多生成图片质量越好，希望后面论文能有更好的评估方法。这不就来了吗。 Inception Score : 论文提出的方式是将所有生成的图片 $\\boldsymbol{x}$ 输入进一个 Inception 分类模型得到它的条件标签分布 $p(y|\\boldsymbol{x})$。包含有意义物体的图像应该有一个较低熵的条件标签分布 $p(y|\\boldsymbol{x})$。而对于积分$\\int p(y \\mid \\boldsymbol{x}=G(z)) d z$ 若有一个较高的熵则表明生成的图像具有多样性。综合考虑这两点得到了 IS分数 的计算公式： $$ \\exp \\left(\\mathbb{E}_{\\boldsymbol{x}} \\operatorname{KL}(p(y \\mid \\boldsymbol{x})|| p(y))\\right) $$ 在网上查了下，IS分数虽然已经有了广泛的应用程度，但还是有很多缺陷的。 ","date":"2022-05-14","objectID":"/improvedgan/:4:0","series":null,"tags":["机器学习","深度学习","论文复现","GAN"],"title":"[论文阅读] Improved GAN","uri":"/improvedgan/#图片质量评估"},{"categories":["深度学习"],"content":"半监督学习 标准的分类模型都是有监督的，通常使用交叉熵函数训练。 论文提出了一个将GAN运用于任何标准分类分类模型实现半监督学习的方法。 比如在 K 分类模型中，将GAN的生成的图片作为第 K+1 类，相应的这个分类模型的输出也改为 K+1类。这时 $p_{model}(y=K+1|\\boldsymbol{x})$ 表示 $\\boldsymbol{x}$ 为假的概率，对应GAN里面的 $1-D(\\boldsymbol{x})$。 这样我们通过最大化 $p_{model}(y=1\\dots K|\\boldsymbol{x})$ 就可以使用无标注的数据上分类模型上训练了，只要我们知道它对应于真实类别 $(1\\dots K)$ 的哪一类。 这时，损失函数变成这样： $$ \\begin{aligned} L \u0026=-\\mathbb{E}_ {\\boldsymbol{x}, y \\sim p_{\\text {data }}(\\boldsymbol{x}, y)}\\left[\\log p_{\\text {model }}(y \\mid \\boldsymbol{x})\\right]-\\mathbb{E}_ {\\boldsymbol{x} \\sim G}\\left[\\log p_ {\\text {model }}(y=K+1 \\mid \\boldsymbol{x})\\right] \\end{aligned} $$ $$ =L_ {\\text {supervised }}+L_ {\\text {unsupervised }}, \\text { where } $$ $$ L_ {\\text {supervised }} =-\\mathbb{E}_ {\\boldsymbol{x}, y \\sim p_ {\\text {data }}(\\boldsymbol{x}, y)} \\log p_ {\\text {model }}(y \\mid \\boldsymbol{x}, y\u003cK+1) $$ $$ L_ {\\text {unsupervised }} =- \\mathbb{E}_ {\\boldsymbol{x} \\sim p_ {\\text {data }}(\\boldsymbol{x})} \\log \\left[1-p_ {\\text {model }}(y=K+1 \\mid \\boldsymbol{x})\\right]+\\mathbb{E}_ {\\boldsymbol{x} \\sim G} \\log \\left[p_ {\\text {model }}(y=K+1 \\mid \\boldsymbol{x})\\right] $$ 可以看出无监督的损失函数就是来自标准的GAN 文中还提到了一个将这个分类模型作为GAN中的判别器同 $G$ 一同训练的方法，这种方法使得G和分类器之间产生了互动。 ","date":"2022-05-14","objectID":"/improvedgan/:5:0","series":null,"tags":["机器学习","深度学习","论文复现","GAN"],"title":"[论文阅读] Improved GAN","uri":"/improvedgan/#半监督学习"},{"categories":["深度学习"],"content":"实验部分 论文对 MINST，CIFAR-10，SVHN和ImageNet 四个数据集进行了实验，我就只看CIFAR-10的吧，毕竟要跟它死磕到底。 GAN中的判别器是中使用了9层带dropout和weight normalization的深度卷积网络。而生成器是一个带BN层的4层深度卷积网络。 分别使用了Feature matching和minibatch discrimination的半监督学习。说实话论文图片的效果还是不咋地，跟我用DCGAN跑出来的效果差不多。 就是这效果图打消了我复现代码的念头，于是标题由论文复现改为了论文阅读 ","date":"2022-05-14","objectID":"/improvedgan/:6:0","series":null,"tags":["机器学习","深度学习","论文复现","GAN"],"title":"[论文阅读] Improved GAN","uri":"/improvedgan/#实验部分"},{"categories":["深度学习"],"content":"总结 虽然感觉没有啥太明显的效果，但是论文的提出的这些技术都是很好的，不知道后面的提出的 GAN 有没有用到这篇论文里的东西。 ","date":"2022-05-14","objectID":"/improvedgan/:7:0","series":null,"tags":["机器学习","深度学习","论文复现","GAN"],"title":"[论文阅读] Improved GAN","uri":"/improvedgan/#总结"},{"categories":["深度学习"],"content":"GAN开始卷起来了 ","date":"2022-05-13","objectID":"/dcgan/:0:0","series":null,"tags":["机器学习","深度学习","论文复现","GAN"],"title":"[论文复现] Deep Convolutional Generative Adversarial Nets (DCGAN)","uri":"/dcgan/#"},{"categories":["深度学习"],"content":"Deep Convolutional Generative Adversarial Nets 论文下载 ","date":"2022-05-13","objectID":"/dcgan/:0:0","series":null,"tags":["机器学习","深度学习","论文复现","GAN"],"title":"[论文复现] Deep Convolutional Generative Adversarial Nets (DCGAN)","uri":"/dcgan/#deep-convolutional-generative-adversarial-nets"},{"categories":["深度学习"],"content":"基本概览 这篇论文给我的第一印象是很长，有16页那么多，之前看的论文基本都10页左右。论文以现在的眼光来看会觉得用CNN替换掉原始GAN中的MLP是很理所当然的事情，但论文提到在当时CNN在无监督学习中的应用是不怎么被关注的 论文的贡献有： 提出并验证了卷积GANs网络结构上的一些限制，使其在大多数情况下能稳定训练（即DCGAN） 使用与训练好的图像分类器作为判别器，与其他无监督算法相比有更好的性能 可视化了GAN学到的滤波器，实验表明不同的滤波器能绘制出不同的图像 展现了生成器的一些有趣的向量运算属性，这使得我们可以对生成样本的语义质量做一些简单的修改 然后提到了之前的图像生成模型在生成想MNIST这种数据集虽然还可以，但是在生成自然图片上效果还是不行（让我想到我在CIFAR-10上跑的GAN，效果惨不忍睹） ","date":"2022-05-13","objectID":"/dcgan/:1:0","series":null,"tags":["机器学习","深度学习","论文复现","GAN"],"title":"[论文复现] Deep Convolutional Generative Adversarial Nets (DCGAN)","uri":"/dcgan/#基本概览"},{"categories":["深度学习"],"content":"模型及训练 在此之前已经有人尝试过用CNN扩展GAN，但是都失败了。作者最开始使用监督学习领域常用的CNN结构试图扩展GAN时也失败了。但是在做了一番模型探索后，确定了一类结构族，这些结构能够提供稳定的训练，并能够训练更高分辨率和更深层次的生成模型（卡多就可以为所欲为吗） 核心方法采用了三个CNN架构的改进方法： 全卷积网络：使用逐步卷积代替确定性空间池化函数（如maxpooling），这样网络可以自己学习空间下采样。用于生成器和判别器中便可以自行学习图像的上下采样（上下采样就是放大缩小） 消除最顶层卷积层的全连接层，就如图像分类里常用的global average pooling那样。（一整个通道做一个average pooling，输出一个值），可以增强模型稳定性，但减缓了收敛速度 使用Batch Normalization。但是直接对所有的层采用批处理规范化会导致样本震荡和模型不稳定，可以通过对生成器的输出层和辨别器的输入层不采用批处理规范化来避免这种情况。 生成器输出层使用Tanh激活函数，其他层使用ReLU激活函数。而在判别器上则使用LeakyReLU激活函数效果更好，特别是在高分辨率图像上。 论文给出了详细的训练细节（太良心了），除了将像素缩放到Tanh的范围[-1, 1]之外，图像没做任何预处理。使用mini-batch SGD训练，batch size为128。权重初始化用的 $(0, 0.02^2)$的正态分布初始化。LeakyReLU的p设为0.2。使用Adam优化器，学习率为0.0002，beta1设为0.5。 终于知道论文为什么这么长了，真的太详细了。 论文剩下部分是一大堆关于验证和可视化的东西。 ","date":"2022-05-13","objectID":"/dcgan/:2:0","series":null,"tags":["机器学习","深度学习","论文复现","GAN"],"title":"[论文复现] Deep Convolutional Generative Adversarial Nets (DCGAN)","uri":"/dcgan/#模型及训练"},{"categories":["深度学习"],"content":"核心代码 卷积层输出大小计算公式： $$ N=(W-K+2P)/S+1 $$ N: 输出大小 W: 图像宽高 K: 卷积核大小 P: 填充值大小 S: 步长大小 转置卷积层输出大小计算公式： $$ N=(W-1)\\times S-2P+K $$ 生成器： # 生成器 class DCGenerator(nn.Module): def __init__(self, in_features, img_shape, init_weights=True): super().__init__() self.img_shape = img_shape # 默认每次放大2倍宽高，用于上采样 def upsampling_block(in_channel, out_channel, normalize=True, activation=None, kernel_size=4, stride=2, padding=1): layers = [nn.ConvTranspose2d(in_channel, out_channel, kernel_size=kernel_size, stride=stride, padding=1, bias=False)] if normalize: layers.append(nn.BatchNorm2d(out_channel)) layers.append(nn.ReLU(inplace=True) if activation is None else activation) return layers self.linear = nn.Sequential( # BN层前面的层bias可以为False nn.Linear(in_features, 1024 * np.prod(self.img_shape[1:]), bias=False), nn.BatchNorm1d(1024 * np.prod(self.img_shape[1:])), nn.ReLU() ) self.net = nn.Sequential( *upsampling_block(1024, 512), # 8 * 8 *upsampling_block(512, 256), # 16 * 16 *upsampling_block(256, 128), # 32 * 32 *upsampling_block(128, 3, False, nn.Tanh()) # 64 * 64 ) if init_weights: for m in self.modules(): if isinstance(m, nn.Conv2d): nn.init.normal_(m.weight, mean=0, std=0.02) if isinstance(m, nn.BatchNorm2d): nn.init.normal_(m.weight, mean=1, std=0.02) if m.bias is not None: nn.init.constant_(m.bias, 0) def forward(self, x): x = self.linear(x) x = x.view(x.shape[0], *self.img_shape) # 变换成二维用于卷积 return self.net(x) 判别器： # 判别器 class DCDiscriminator(nn.Module): def __init__(self, img_shape, init_weights=True): super().__init__() # 默认每次缩小2倍宽高，用于下采样 def downsampling_block(in_channel, out_channel, normalize=True, activation=None, padding=1): layers = [nn.Conv2d(in_channel, out_channel, kernel_size=4, stride=2, padding=padding, bias=False)] if normalize: layers.append(nn.BatchNorm2d(out_channel)) layers.append(nn.LeakyReLU(0.2, inplace=True) if activation is None else activation) return layers self.net = nn.Sequential( *downsampling_block(3, 128, False), # 32 * 32 *downsampling_block(128, 256), # 16 * 16 *downsampling_block(256, 512), # 8 * 8 *downsampling_block(512, 1024), # 4 * 4 *downsampling_block(1024, 1, False, activation=nn.Sigmoid(), padding=0), #nn.AdaptiveAvgPool2d((1, 1)), nn.Sigmoid() ) if init_weights: for m in self.modules(): if isinstance(m, nn.Conv2d): nn.init.normal_(m.weight, mean=0, std=0.02) if isinstance(m, nn.BatchNorm2d): nn.init.normal_(m.weight, mean=1, std=0.02) if m.bias is not None: nn.init.constant_(m.bias, 0) def forward(self, images): y = self.net(images) return y.view(y.shape[0], -1) 判别器的输出层那里我看网上的代码基本都是用的padding为0的卷积层，然后我有在动漫头像数据集上试过论文提到的全局average pooling层（注释的代码）。同样训练了一个epoch后，用全局池化的效果的确是差一些，但训练速度提升了点，没试过一直训练下去会怎么样 其余部分与原始的GAN没什么太大区别 ","date":"2022-05-13","objectID":"/dcgan/:3:0","series":null,"tags":["机器学习","深度学习","论文复现","GAN"],"title":"[论文复现] Deep Convolutional Generative Adversarial Nets (DCGAN)","uri":"/dcgan/#核心代码"},{"categories":["深度学习"],"content":"效果 我依然是在CIFAR-10上训练的，虽然论文中写到他们从未在CIFAR-10上训练过，但为了和之前做的GAN有个直观的对比，所以还是在CIFAR-10上训练。 虽然作者没在CIFAR-10训练，但是他们在ImageNet-1k上做的预训练模型在CIFAR-10上提取特征后在分类的准确度仍然很高，说明这个模型有很高的鲁棒性 一开始在CIFAR-10上训练的是时候一直没什么效果，经过在动漫头像上的效果对比后排除了模型了问题，所以那就是数据分布的问题了，于是便把batch size 调大一点（由原论文的128调到512），让模型一次”看到“的数据多一点，效果立竿见影，终于跑出了像样的图片了。 30 epoch： 50 epoch： 80 epoch： 比原生GAN好点，但还是看不出生成的到底是啥，再也不到 CIFAR-10上跑GAN了 并不是epoch越多效果就更好，有可能20epoch的时候效果已经还可以，30的时候又很差，40epoch又好起来了。单看loss很难确定哪个效果好，不知道后面的论文有没有更好的验证方法。 ","date":"2022-05-13","objectID":"/dcgan/:4:0","series":null,"tags":["机器学习","深度学习","论文复现","GAN"],"title":"[论文复现] Deep Convolutional Generative Adversarial Nets (DCGAN)","uri":"/dcgan/#效果"},{"categories":["深度学习"],"content":"总结 没有像论文里那样先做预训练。 一开始我在CIFAR10上跑的时候loss没有像正常的GAN那样起伏，调了很久，最后发现原因是判别器的输出层接了BN层导致的。因为输出的是概率，被BN层一处理就会有问题了。应该是个常识问题，我傻逼了。 还有就是不同数据集效果也差很大，像动漫头像（CrypkoFaces）那样的数据集训练一个epoch就能有明显效果。可能因为动漫头像就一类数据，数据分布比较简单更容易拟合，而像CIFAR10那样的分类数据集的分布要复杂点， One epoch on CrypkoFaces： 完整代码：https://github.com/xxy-im/Just4GAN 直接 python train.py --config ./config/dcgan.yaml 就可以默认训练CIFAR-10了。 默认训练CIFAR10，如果需要训练自定义数据可能需要改几行代码 coding十分钟，debug俩小时 ","date":"2022-05-13","objectID":"/dcgan/:5:0","series":null,"tags":["机器学习","深度学习","论文复现","GAN"],"title":"[论文复现] Deep Convolutional Generative Adversarial Nets (DCGAN)","uri":"/dcgan/#总结"},{"categories":["深度学习"],"content":"生死看淡，不服就GAN ","date":"2022-05-08","objectID":"/gan/:0:0","series":null,"tags":["机器学习","深度学习","论文复现","GAN"],"title":"[论文复现] Generative Adversarial Nets (原生GAN)","uri":"/gan/#"},{"categories":["深度学习"],"content":"Generative Adversarial Nets 论文下载 ","date":"2022-05-08","objectID":"/gan/:0:0","series":null,"tags":["机器学习","深度学习","论文复现","GAN"],"title":"[论文复现] Generative Adversarial Nets (原生GAN)","uri":"/gan/#generative-adversarial-nets"},{"categories":["深度学习"],"content":"基本概览 文中提到在此之前，深度生成模型没什么进展是因为在最大似然估计和相关策略出现的许多棘手的概率问题很难找到合适的计算方式，（这里说的是G和D的Divergence吗？不懂）以及在生成模型中那些已经在分类模型里很有用的分层线性单元的优势显现不出来。所以提出了一个全新的生成模型，绕过这些难点。 简而言之就是以前的方法都是想着先构造出样本的概率分布函数，然后给函数提供些参数用于学习（最大化对数似然函数？）。但这东西很难算，尤其是维度比较高的时候。 通过对抗(adversarial)的方式，同时训练两个模型，即生成器(Generator)，一个判别器(Discriminator)，分别用G和D表示。 生成器通过捕捉真实样本(训练数据)的数据分布用于生成数据，判别器用于对一个样本进行评估，给出其来自真实样本和由生成器生成的概率，即判别数据是real or synthesis，所以判别器其实就是个二分类模型。 固定G训练D，再固定D训练G，这样不断对抗的训练。论文中把G比喻成造假币的，D比喻成警察，双方互相促使着对方的技术手段进步，直到假币无法辨别。（零和博弈） ","date":"2022-05-08","objectID":"/gan/:1:0","series":null,"tags":["机器学习","深度学习","论文复现","GAN"],"title":"[论文复现] Generative Adversarial Nets (原生GAN)","uri":"/gan/#基本概览"},{"categories":["深度学习"],"content":"模型及训练 论文中的生成器和判别器都是用的多层感知机(MLP)，这样便可以使用backpropagation，SGD和dropout这些手段来训练这两个模型。 生成器的输入是随机噪声(就均匀分布，高斯分布这样的东西，1维到高维都可以)。 判别器的输出是0到1的标量，越接近1表示越真。 生成器 $G$ 的目标是要使得输入噪声 $z$ 后生成的图像 $G(z)$ 在判别器 $D$ 中得到的分数 $D(G(z))$ 很高。即 $1-D(G(z))$ 要很小，论文中对其取对数，于是生成器的目标是 $\\min(log(1-D(G(z)))$。 判别器 $D$ 的目标则是对于输入的真实数据 $x$ ，$D(x)$ 的值越大越好，对其取对数，即 $max(log(D(x)))$。同时对 $G(z)$ 给出的分数 $D(G(z))$ 要越小越好，即$\\max(log(1-D(G(z)))$。组合起来得到$\\max(log(D(x))+log(1-D(G(z)))$，这其实就是最大化交叉熵函数的负数。 综上两点，GAN的目标函数是这样的： $$ \\min_{G}\\max_{D}V(D, G)=\\mathbb{E}_{\\boldsymbol{x}\\sim p_{\\text {data }}(\\boldsymbol{x})}[\\log{D}(\\boldsymbol{x})]+\\mathbb{E}_{\\boldsymbol{z}\\sim p_{\\boldsymbol{z}}(\\boldsymbol{z})}[\\log (1-D(G(\\boldsymbol{z})))] $$ 但是在训练刚开始的时候生成的数据几乎都是一眼假，判别器给出的分数 $D(G(z))$ 很接近0，导致$log(1-D(G(z))$的梯度太小从而无法训练，所以实际训练时候还是把生成器的目标改为$\\max(logD(G(z)))$。并且对于固定判别器训练生成器的情况，前一项 $max(log(D(x)))$ 可以视为常数1，所以生成器的目标函数可以视为最大化$D(G(z)))$与1的交叉熵的负数。这样目标函数就统一为了最大化交叉熵函数的负数，即最小化交叉熵函数。所以GAN的loss函数为BCELoss。 交叉熵来用于预测概率与真实概率之间的差距。 分别对那两个对数函数求期望后相加。(其实就是交叉熵。) 固定判别器 $D$ 的情况下，目标函数最小化；（计算$D(G(z)))$与全1的交叉熵，从而优化生成器） 固定生成器 $G$ 的情况下，目标函数最大化。（计算$D(x)$与1的交叉熵 和 $D(G(z))$与0的交叉熵） 不断交替训练，然后得到一个数值解。由于训练判别器的内层循环的计算代价非常高，而且在有限的数据集上会导致过拟合。论文中采用的方法是训练 $k$ 次 $D$ 再训练 $1$ 次 $G$ 。(这里 $1$ 次是指一个mini-batch)。让 $G$ 走慢点，这样能维持 $D$ 在最优解附近。 理想状态是 $G$ 和 $D$ 有足够的容量，在不断地交替训练后，生成的数据分布和真实的数据分布重合，即 $p_g = p_{data}$， 判别器无法分别真假分布，使得 $D(x)=\\frac{1}{2}$ 。 GAN是出了名的难训练，因为容易出现海奥维提卡现象(the Helvetica Scenario), 也叫做模型坍塌(Mode collapse)。生成器可能发现了某些输出能很好的骗过判别器，使得判别器分辨不出真假，于是生成器和判别器就都开摆了，不会再进步了。 ","date":"2022-05-08","objectID":"/gan/:2:0","series":null,"tags":["机器学习","深度学习","论文复现","GAN"],"title":"[论文复现] Generative Adversarial Nets (原生GAN)","uri":"/gan/#模型及训练"},{"categories":["深度学习"],"content":"核心代码 前面提到了生成器和判别器其实都是多层感知机。 生成器的输出大小等于图像拉成一维向量的长度（注意像素是整型），判别器输出为图片为real的概率。比如我想在CIFAR-10 上跑GAN，所以生成器最后的输出为 $3\\times32\\times32$ 生成器 import numpy as np import torch from torch import nn # 生成器 class Generator(nn.Module): def __init__(self, in_features, img_shape, init_weights = False): super().__init__() self.img_shape = img_shape self.net = nn.Sequential( nn.Linear(in_features, 256), nn.ReLU(inplace=True), nn.Linear(256, 512), nn.BatchNorm1d(512), nn.ReLU(inplace=True), nn.Linear(512, 1024), nn.BatchNorm1d(1024), nn.ReLU(inplace=True), nn.Linear(1024, 2048), nn.BatchNorm1d(2048), nn.ReLU(inplace=True), nn.Linear(2048, np.prod(img_shape)), nn.Tanh() ) if init_weights: for m in self.modules(): if isinstance(m, nn.Linear): nn.init.normal_(m.weight) if m.bias is not None: nn.init.constant_(m.bias, 0) def forward(self, z): gz = self.net(z) return gz.view(-1, *self.img_shape) 判别器 class Discriminator(nn.Module): def __init__(self, img_shape, init_weights = True): super().__init__() self.net = nn.Sequential( nn.Linear(np.prod(img_shape), 1024), nn.ReLU(inplace=True), nn.Linear(1024, 512), nn.ReLU(inplace=True), nn.Linear(512, 256), nn.ReLU(inplace=True), nn.Linear(256, 1), nn.Sigmoid() ) if init_weights: for m in self.modules(): if isinstance(m, nn.Linear): nn.init.xavier_uniform_(m.weight) if m.bias is not None: nn.init.constant_(m.bias, 0) def forward(self, imgs): x = imgs.view(imgs.shape[0], -1) return self.net(x) Loss计算 z = torch.randn((bs, 128), device=device) # 随机噪声 real = torch.ones((bs, 1), device=device) # 全真标签 fake = torch.zeros((bs, 1), device=device) # 全假标签 loss = nn.BCELoss() # 计算判别器loss r_loss = loss(D(imgs), real) # 识别真实图片的loss f_loss = loss(D(gz), fake) # 识别假图片的loss D_loss = (r_loss + f_loss) / 2 # 取平均 # 计算生成器loss G_loss = loss(D(G(z)), real) ","date":"2022-05-08","objectID":"/gan/:3:0","series":null,"tags":["机器学习","深度学习","论文复现","GAN"],"title":"[论文复现] Generative Adversarial Nets (原生GAN)","uri":"/gan/#核心代码"},{"categories":["深度学习"],"content":"效果 论文中对于CIFAR-10有对比两种不同方案 普通MLP的G和D G使用转置卷积，D使用卷积 反正对比的图片我觉得两种效果都差不多，都不怎么好，毕竟是第一个GAN，重要的是思想。 下面是我自己在CIFAR-10上跑出来的效果 100 epoch： 200 epoch： 600 epoch： ","date":"2022-05-08","objectID":"/gan/:4:0","series":null,"tags":["机器学习","深度学习","论文复现","GAN"],"title":"[论文复现] Generative Adversarial Nets (原生GAN)","uri":"/gan/#效果"},{"categories":["深度学习"],"content":"总结 效果不太好，但还是能看出来它好像真的有在努力画出真实图像。训练的时候我也遇到了模型坍塌的问题，后面不管怎么train都没变化，不知道是不是权重初始化的问题。之前用的xavier权重初始化，效果更差，索性不初始化了还比之前好点，为什么会这样不知道有没有大佬解答下。 完整代码：https://github.com/xxy-im/Just4GAN 直接 python train.py --config ./config/vanilla.yaml 就可以默认训练CIFAR-10了。 不太会python，代码写的菜，轻喷。 ","date":"2022-05-08","objectID":"/gan/:5:0","series":null,"tags":["机器学习","深度学习","论文复现","GAN"],"title":"[论文复现] Generative Adversarial Nets (原生GAN)","uri":"/gan/#总结"},{"categories":["深度学习"],"content":"持续更新中… ","date":"2022-04-22","objectID":"/ml-terms/:0:0","series":null,"tags":["机器学习","深度学习"],"title":"机器学习中的一些评价指标名词解释","uri":"/ml-terms/#"},{"categories":["深度学习"],"content":"TP、TN、FP、FN TP(True Positive, 真正): 实际为正，预测为正 TN(True Negative, 真负): 实际为负，预测为负 FP(False Positive, 假正): 实际为负，预测为正 FN(False Negative, 假负): 实际为正，预测为负 $$ \\begin{array}{|c|c|} \\hline TP \u0026 FN\\\\ \\hline FP \u0026 TN\\\\ \\hline \\end{array} $$ 这东西就叫混淆矩阵(Confusion matrix) $TP+TN+FP+FN$ 为总样本数 $TP+FN$ 为实际正样本数 $TP+FP$ 为预测正样本数 $TN+FP$ 为实际负样本数 $TN+FN$ 为预测负样本数 ","date":"2022-04-22","objectID":"/ml-terms/:1:0","series":null,"tags":["机器学习","深度学习"],"title":"机器学习中的一些评价指标名词解释","uri":"/ml-terms/#tptnfpfn"},{"categories":["深度学习"],"content":"TPR、FPR TPR(True Positive Rate): 正例样本被正确预测出来的比例，和Recall相等 $$ TPR = \\frac{TP}{TP+FN} $$ FPR(False Positive Rate): 误分类为正实际为负的样本占所有负样本的比例 $$ FPR = \\frac{FP}{TN+FP} $$ ","date":"2022-04-22","objectID":"/ml-terms/:2:0","series":null,"tags":["机器学习","深度学习"],"title":"机器学习中的一些评价指标名词解释","uri":"/ml-terms/#tprfpr"},{"categories":["深度学习"],"content":"Precision(精确率、查准率) 所有预测为正的样本中预测正确的比例 $$ Precision = \\frac{TP}{TP+FP} $$ ","date":"2022-04-22","objectID":"/ml-terms/:3:0","series":null,"tags":["机器学习","深度学习"],"title":"机器学习中的一些评价指标名词解释","uri":"/ml-terms/#precision精确率查准率"},{"categories":["深度学习"],"content":"Recall(召回率、查全率) 正例样本被正确预测出来的比例 $$ Recall = \\frac{TP}{TP+FN} $$ ","date":"2022-04-22","objectID":"/ml-terms/:4:0","series":null,"tags":["机器学习","深度学习"],"title":"机器学习中的一些评价指标名词解释","uri":"/ml-terms/#recall召回率查全率"},{"categories":["深度学习"],"content":"Accuracy(准确率) 预测正确的比例 $$ Acc = \\frac{TP+TN}{TP+TN+FP+FN} $$ ","date":"2022-04-22","objectID":"/ml-terms/:5:0","series":null,"tags":["机器学习","深度学习"],"title":"机器学习中的一些评价指标名词解释","uri":"/ml-terms/#accuracy准确率"},{"categories":["深度学习"],"content":"F1score 综合评价Precision和Recall的一个评价指标 这篇文章的分析很好 $$ F1-score = \\frac{2Precision\\times Recall}{Precision+Recall} $$ ","date":"2022-04-22","objectID":"/ml-terms/:6:0","series":null,"tags":["机器学习","深度学习"],"title":"机器学习中的一些评价指标名词解释","uri":"/ml-terms/#f1score"},{"categories":["深度学习"],"content":"PR曲线 横坐标为Recall，纵坐标为Precision 将每个样本按置信度排序后，分别计算每个样本作为阈值情况下的Recall和Precision，然后绘制曲线图 ","date":"2022-04-22","objectID":"/ml-terms/:7:0","series":null,"tags":["机器学习","深度学习"],"title":"机器学习中的一些评价指标名词解释","uri":"/ml-terms/#pr曲线"},{"categories":["深度学习"],"content":"ROC曲线 全称为Receiver Operating Characteristic(“受试者工作特征”) 横坐标为FPR，纵坐标为TPR ","date":"2022-04-22","objectID":"/ml-terms/:8:0","series":null,"tags":["机器学习","深度学习"],"title":"机器学习中的一些评价指标名词解释","uri":"/ml-terms/#roc曲线"},{"categories":["深度学习"],"content":"AUC(Area under Curve) ROC曲线下的面积，介于0.1和1之间，作为数值可以直观的评价分类器的好坏，值越大越好。 ","date":"2022-04-22","objectID":"/ml-terms/:9:0","series":null,"tags":["机器学习","深度学习"],"title":"机器学习中的一些评价指标名词解释","uri":"/ml-terms/#aucarea-under-curve"},{"categories":["深度学习"],"content":"IOU(Intersection over Union) 用来预测的锚框和真实边界框(ground-truth bounding box)的交并比 $$ IOU = \\frac{A\\cap B}{A\\cup B} $$ ","date":"2022-04-22","objectID":"/ml-terms/:10:0","series":null,"tags":["机器学习","深度学习"],"title":"机器学习中的一些评价指标名词解释","uri":"/ml-terms/#iouintersection-over-union"},{"categories":["深度学习"],"content":"AP和mAP 全称为Average Precision和mean Average Precision，是目标检测任务的评价指标 在目标检测任务中 TP为 $IOU \u003e IOU_{threshold}$ 的锚框数量(同一ground-truth bounding box只计算一次) FP 为 $IOU \\leq IOU_{threshold}$ 的锚框数量或者是检测到同一个 GT 的多余检测框的数量 FN为没有检测到的 GT 的数量 TN在 mAP 评价指标中不会使用到 AP是计算某一类 PR曲线下的面积，mAP则是计算所有类别 PR曲线下面积的平均值。 VOC2010之前和VOC2010之后的mAP计算方法不同，可参考GluonCV库中的voc_detection.py里的两种计算方式 ","date":"2022-04-22","objectID":"/ml-terms/:11:0","series":null,"tags":["机器学习","深度学习"],"title":"机器学习中的一些评价指标名词解释","uri":"/ml-terms/#ap和map"},{"categories":["深度学习"],"content":"信息熵 反映的是要表示一个概率分布需要的平均信息量 $$ H=-\\sum_{i=1}^{N} p\\left(x_{i}\\right) \\log p\\left(x_{i}\\right) $$ ","date":"2022-04-22","objectID":"/ml-terms/:12:0","series":null,"tags":["机器学习","深度学习"],"title":"机器学习中的一些评价指标名词解释","uri":"/ml-terms/#信息熵"},{"categories":["深度学习"],"content":"交叉熵 $$ L=\\frac{1}{N} \\sum_{i} L_{i}=\\frac{1}{N} \\sum_{i}-\\left[y_{i} \\cdot \\log \\left(p_{i}\\right)+\\left(1-y_{i}\\right) \\cdot \\log \\left(1-p_{i}\\right)\\right] $$ 多分类情况： $$ L=\\frac{1}{N} \\sum_{i} L_{i}=-\\frac{1}{N} \\sum_{i} \\sum_{c=1}^{M} y_{i c} \\log \\left(p_{i c}\\right) $$ $M$: 类别数 $y_{ic}$: 样本 $i$ 的真实类别为 $c$ 则该值为1，否则为0 $p_{ic}$: 对样本 $i$ 预测为 $c$ 类的概率 ","date":"2022-04-22","objectID":"/ml-terms/:13:0","series":null,"tags":["机器学习","深度学习"],"title":"机器学习中的一些评价指标名词解释","uri":"/ml-terms/#交叉熵"},{"categories":["深度学习"],"content":"KL散度 (Kullback-Leibler Divergence) KL散度又叫相对熵，是用于衡量两个概率分布相似性的一个度量指标。 $$ D_{K L}(p | q)=\\sum_{i=1}^{N} p\\left(x_{i}\\right) \\cdot\\left(\\log p\\left(x_{i}\\right)-\\log \\left(q\\left(x_{i}\\right)\\right)\\right. $$ 或者 $$ D_{K L}(p | q)=\\sum_{i=1}^{N} p\\left(x_{i}\\right) \\cdot \\log \\frac{p\\left(x_{i}\\right)}{q\\left(x_{i}\\right)} $$ 散度越小，说明概率 $p$ 与概率 $q$ 之间越接近，那么估计的概率分布于真实的概率分布也就越接近。 ","date":"2022-04-22","objectID":"/ml-terms/:14:0","series":null,"tags":["机器学习","深度学习"],"title":"机器学习中的一些评价指标名词解释","uri":"/ml-terms/#kl散度-kullback-leibler-divergence"},{"categories":["深度学习"],"content":"JS散度 (Jenson’s Shannon) 由于KL散度的不对称性问题使得在训练过程中可能存在一些问题，为了解决这个问题，在KL散度基础上引入了JS散度。 不太懂，直接看这个吧 https://blog.csdn.net/weixin_44441131/article/details/105878383 continue… ","date":"2022-04-22","objectID":"/ml-terms/:15:0","series":null,"tags":["机器学习","深度学习"],"title":"机器学习中的一些评价指标名词解释","uri":"/ml-terms/#js散度-jensons-shannon"},{"categories":["C++"],"content":"进程与线程 这个没啥好讲的吧，但凡稍微学了点操作系统或者复习了408的应该都知道了。 简单说下它们之间的关系： 线程从属于进程，一个进程可以拥有多个线程 每个线程除了独立拥有很小的一点栈外，共享进程的内存空间 ","date":"2022-04-20","objectID":"/multithread/:1:0","series":null,"tags":["C++","编程技巧"],"title":"[C++技法] 多线程编程","uri":"/multithread/#进程与线程"},{"categories":["C++"],"content":"Why多线程 用我们最常用的浏览器来举例，通常我们都会在浏览器上很多标签页，有的页面听歌，有的用来搜索，还有用来下载文件。浏览器不可能让你听完歌再继续后面的操作吧，这时候就需要多线程了。一个线程处理听歌，一个线程处理下载，等等等等。实现单进程多任务场景。 在任务管理器中可以看到Chrome开了这么多线程。(明明就开了几个网页，给我开了这么多个线程，咱也不懂) Chrome浏览器进程点击放大 \" Chrome浏览器进程 ","date":"2022-04-20","objectID":"/multithread/:1:1","series":null,"tags":["C++","编程技巧"],"title":"[C++技法] 多线程编程","uri":"/multithread/#why多线程"},{"categories":["C++"],"content":"现代C++的多线程 C++11之前，需要多线程编程的话需要使用pthread库，C++11开始引入了std::thread实现多线程。但这玩意儿其实还是用pthread实现的，所以用g++编译的话还得加-lpthread… // std::thread 构造函数 thread() noexcept; // 1 thread( thread\u0026\u0026 other ) noexcept; // 2 template\u003c class Function, class... Args \u003e explicit thread( Function\u0026\u0026 f, Args\u0026\u0026... args ); // 3 thread( const thread\u0026 ) = delete; 主要用第三个比较多，参数可以用lambda表达式。貌似只要是Callable的就行，官方示例里有个定义的operator()的类也可以成功创建线程。 简单实现上面浏览器的场景 #include \u003ciostream\u003e#include \u003cthread\u003e#include \u003cstring\u003e // 功能函数 void BrowsePage() { for (int i = 0; i \u003c 10; i++) { std::cout \u003c\u003c \"Searching something on Google..... \" \u003c\u003c std::endl; std::this_thread::sleep_for(std::chrono::seconds(1)); // 新标准的睡眠函数，不再需要用sleep这种了 } } void ListenMusic() { for (int i = 0; i \u003c 10; i++) { std::cout \u003c\u003c \"正在播放《以父之名》..... \" \u003c\u003c std::endl; std::this_thread::sleep_for(std::chrono::seconds(2)); } } void Download(std::string filename) { for (int i = 0; i \u003c 20; i++) { std::cout \u003c\u003c \"Downloading \" \u003c\u003c filename \u003c\u003c \" ( \" \u003c\u003c i * 10 \u003c\u003c \"% )......\" \u003c\u003c std::endl; std::this_thread::sleep_for(std::chrono::seconds(1)); } std::cout \u003c\u003c filename \u003c\u003c \"Download completed\" \u003c\u003c std::endl; } int main() { std::thread t1(ListenMusic); std::thread t2([\u0026]() { std::string filename; std::cin \u003e\u003e filename; Download(filename); }); BrowsePage(); t1.join(); // 相当于一个wait，等待这个线程结束了再继续执行后面的语句 t2.join(); return 0; } 运行后可以边浏览网页边输入需要下载的文件然后回车开始下载。如果没加join的话就会有可能导致程序已经结束了但t1,t2线程还没结束但也会随着进程结束而强行终止执行。 注意 BrowsePage()这里我没用线程来执行，所以必须放在最后面，如果放在t1或者t2线程前面的话那么就会导致线程会等待BrowsePage执行完才会开始执行。 std::thread也是遵循RAII思想的，所以当线程所在函数执行结束时会自动调用std::thread的析构函数。但是可以使用detach()将线程分离，使其不再由当前对象管理，而是在线程运行结束后自动销毁。不过这东西也不怎么好，就不介绍了 ","date":"2022-04-20","objectID":"/multithread/:2:0","series":null,"tags":["C++","编程技巧"],"title":"[C++技法] 多线程编程","uri":"/multithread/#现代c的多线程"},{"categories":["C++"],"content":"线程池 最low的线程池可以用std::vector实现 std::vector\u003cstd::thread\u003e tpool; void DoIt() { std::thread t1(BrowsePage); std::thread t2(ListenMusic); std::thread t3([\u0026]() { std::string filename; std::cin \u003e\u003e filename; Download(filename); }); tpool.push_back(std::move(t1)); // std::thread 禁止拷贝 tpool.push_back(std::move(t2)); tpool.push_back(std::move(t3)); } int main() { DoIt(); for (auto\u0026 t : tpool) { t.join(); } return 0; } 但是这样手动把每个线程join实在太low了。 可以自定义一个管理线程池的类，在类的析构函数中加入线程的join即可。(其实就是把for循环换了个地方那它自动会执行，看起来代码整洁点而已) C++20 中的std::jthread会在析构时候自动join ","date":"2022-04-20","objectID":"/multithread/:2:1","series":null,"tags":["C++","编程技巧"],"title":"[C++技法] 多线程编程","uri":"/multithread/#线程池"},{"categories":["C++"],"content":"同步与互斥 就像进程需要处理临界区互斥一样，多线程中因为共享着进程的内存空间，所以也需要有互斥手段。当然同步也是一样的。 借用多进程互斥里经典的存钱取钱的场景(虽然现实中不可能在一个进程里存钱又取钱，但道理都相通嘛) // 假设当前余额为0，现在在ATM机上先存1000个w，在取500个w // 别在意故事细节 #include \u003ciostream\u003e#include \u003cthread\u003e int money = 0; // 当前余额 void deposit(int m) { int cur = money; // 得先把在的余额取出来吧 m = m \u003e 10000 ? 10000 : m; // ATM机一次最多一个w for (volatile int i = 0; i \u003c 100; i++); // 假装有个后台处理过程 cur += m; money = cur; // 然后新的余额 } void withdraw(int m) { int cur = money; m = m \u003e 10000 ? 10000 : m; // ATM机一次最多一个w for (volatile int i = 0; i \u003c 100; i++); cur -= m; money = cur; } int main() { std::thread t1([\u0026] { for (int i = 0; i \u003c 1000; i++) deposit(10000); }); std::thread t2([\u0026] { for (int i = 0; i \u003c 500; i++) withdraw(10000); }); t1.join(); t2.join(); std::cout \u003c\u003c money \u003c\u003c std::endl; return 0; } 多次运行后会发现结果都不同。有时钱多有时钱少了。这时就需要用到互斥手段以保证程序运行的正确性了。 ","date":"2022-04-20","objectID":"/multithread/:3:0","series":null,"tags":["C++","编程技巧"],"title":"[C++技法] 多线程编程","uri":"/multithread/#同步与互斥"},{"categories":["C++"],"content":"std::mutex 看名字也知道是个互斥锁，用来给资源上锁的。修改两个功能函数。 #include \u003cmutex\u003e // 引入头文件std::mutex mtx; // 定义一个互斥锁 void deposit(int m) { mtx.lock(); // 上锁 int cur = money; // 得先把在的余额取出来吧 m = m \u003e 10000 ? 10000 : m; // ATM机一次最多一个w for (volatile int i = 0; i \u003c 100; i++); // 假装有个后台处理过程 cur += m; money = cur; // 然后新的余额 mtx.unlock(); // 用完money解锁 } void withdraw(int m) { mtx.lock(); int cur = money; m = m \u003e 10000 ? 10000 : m; // ATM机一次最多一个w for (volatile int i = 0; i \u003c 100; i++); cur -= m; money = cur; mtx.unlock(); } mtx.lock()如果加锁失败会一直尝试上锁直到成功为止，还可以使用mtx.try_lock()仅尝试一次上锁，成功返回true，失败返回false。 ","date":"2022-04-20","objectID":"/multithread/:3:1","series":null,"tags":["C++","编程技巧"],"title":"[C++技法] 多线程编程","uri":"/multithread/#stdmutex"},{"categories":["C++"],"content":"死锁 有互斥当然就会有死锁。 std::lock: 一次性执行多个互斥锁的lock()，也可以作为一种防止死锁的手段 std::recursive_mutex: 递归互斥锁，当同一个线程对一个资源多次上锁也会造成死锁，如果一定要写这样的代码的话可以用这个互斥锁防止死锁。 ","date":"2022-04-20","objectID":"/multithread/:4:0","series":null,"tags":["C++","编程技巧"],"title":"[C++技法] 多线程编程","uri":"/multithread/#死锁"},{"categories":["C++"],"content":"读写者问题 针对读写者问题，C++14开始引入了一个专门的读写锁std::shared_mutex，比用其他互斥锁实现读写者问题性能提升了很多。 std::shared_mutex有两对加锁解锁方式: lock()和unlock(): 互斥性的，用于写者线程 lock_shared()和unlock_shared(): 共享性的，lock后其他线程也可以访问，可以用于读者线程 除了用std::shared_mutex还可以用std::shared_lock\u003c\u003e模板函数把其他的互斥锁用shared方式上锁。 ","date":"2022-04-20","objectID":"/multithread/:5:0","series":null,"tags":["C++","编程技巧"],"title":"[C++技法] 多线程编程","uri":"/multithread/#读写者问题"},{"categories":["C++"],"content":"条件变量 std::condition_variable，类似多进程里的信号量 ","date":"2022-04-20","objectID":"/multithread/:6:0","series":null,"tags":["C++","编程技巧"],"title":"[C++技法] 多线程编程","uri":"/multithread/#条件变量"},{"categories":["C++"],"content":"生产者消费者 用条件变量实现生产者消费者问题 #include \u003ciostream\u003e#include \u003cvector\u003e#include \u003crandom\u003e#include \u003cthread\u003e#include \u003cmutex\u003e#include \u003ccondition_variable\u003e int products[100]; // 只能存放100个商品 int count = 0; // 当前商品容量 std::mutex mtx; std::condition_variable cv; std::default_random_engine random; std::uniform_int_distribution\u003cint\u003e dis(0, 1000); // 生产者线程 void producer() { std::unique_lock\u003cstd::mutex\u003e lck(mtx); // =执行mtx.lock() cv.wait(lck, [\u0026]() {return count \u003c 100; }); std::this_thread::sleep_for(std::chrono::milliseconds(100)); // 生产耗时100ms products[count++] = dis(random); // 随机生产个0-1000均匀分布的商品编号 lck.unlock(); cv.notify_one(); // 唤醒一个条件变量 std::cout \u003c\u003c \"生产了一件商品\" \u003c\u003c products[count-1] \u003c\u003c \"，当前商品数为 \" \u003c\u003c count \u003c\u003c std::endl; } void consumer() { std::unique_lock\u003cstd::mutex\u003e lck(mtx); // =执行mtx.lock() cv.wait(lck, [\u0026]() {return count \u003e 0; }); count--; lck.unlock(); cv.notify_one(); std::cout \u003c\u003c \"卖出了一件商品，当前商品数为 \" \u003c\u003c count \u003c\u003c std::endl; } int main() { // 一个生产者，两个消费者 std::thread t1([\u0026]() { while (1) { producer(); } }); std::thread t2([\u0026]() { while (1) { std::this_thread::sleep_for(std::chrono::milliseconds(200)); // 线程2卖东西要200ms consumer(); } }); std::thread t3([\u0026]() { while (1) { std::this_thread::sleep_for(std::chrono::milliseconds(300)); // 线程3卖东西要300ms consumer(); } }); t1.join(); t2.join(); t3.join(); return 0; } ","date":"2022-04-20","objectID":"/multithread/:6:1","series":null,"tags":["C++","编程技巧"],"title":"[C++技法] 多线程编程","uri":"/multithread/#生产者消费者"},{"categories":["C++"],"content":"其他 std::async: 也可用于创建线程，自身返回一个std::future。可以捕获返回值，同时可以配合wait()和wait_for使用。加上std::launch::deferred参数可以是其更加灵活。 std::promise: std::async其实就是用这东西实现的，你可以用这个自己手动实现std::async，C++就是这么贴心，帮你做了还告诉你怎么做的 🐶。 std::lock_guard: 一个符合RAII的std::mutex，构造时会自动执行lock()，析构时自动unlock()。 std::unique_lock: (一般推荐用这个) 更灵活的std::lock_guard，因为std::lock_guard严格的在析构时才会unlock()，而有时需要提前unlock()就可以用这个。 还可以用std::try_to_lock参数实现std::mutex的try_lock()的效果。还可以用std::mutex来初始化std::unique_lock 还可以在构造时使用std::defer_lock来推迟执行lock()。(反正就奇奇怪怪的需求C++都能满足你。 std::timed_mutex: 一个可以设置等待时间的互斥锁，try_lock_for()函数中用std::chrono设定时间，还可以使用try_lock_until() std::scoped_lock: RAII版本的std::lock。 std::recursive_timed_mutex: 带time版本的std::recursive_mutex。 std::atomic: 原子类型对象，锁住内存总线，让CPU不去进行乱序执行优化策略。所以从不同线程访问原子类型对象不会导致数据竞争(data race)。 ","date":"2022-04-20","objectID":"/multithread/:7:0","series":null,"tags":["C++","编程技巧"],"title":"[C++技法] 多线程编程","uri":"/multithread/#其他"},{"categories":["C++"],"content":"C++17开始引入的类模板实参推导 ","date":"2022-04-19","objectID":"/ctad/:0:0","series":null,"tags":["C++","编程技巧"],"title":"[C++技法] CTAD (since C++17)","uri":"/ctad/#"},{"categories":["C++"],"content":"使用类模板 ","date":"2022-04-19","objectID":"/ctad/:0:0","series":null,"tags":["C++","编程技巧"],"title":"[C++技法] CTAD (since C++17)","uri":"/ctad/#使用类模板"},{"categories":["C++"],"content":"远古C++ 在远古C++中实例化一个类模板往往需要将参数类型全部写出来 比如使用STL中的std::pair std::pair\u003cint, double\u003e p = std::make_pair\u003cint, double\u003e(2, 1.5); 可以看到代码非常冗余，如果遇到更长的类名简直看不下去。 ","date":"2022-04-19","objectID":"/ctad/:1:0","series":null,"tags":["C++","编程技巧"],"title":"[C++技法] CTAD (since C++17)","uri":"/ctad/#远古c"},{"categories":["C++"],"content":"C++11 然后到了C++11引入了auto自动推断类型 auto p = std::make_pair\u003cint, double\u003e(2, 1.5); 代码一下缩短了很多，这里\u003cint, double\u003e其实也是不用写的。 ","date":"2022-04-19","objectID":"/ctad/:2:0","series":null,"tags":["C++","编程技巧"],"title":"[C++技法] CTAD (since C++17)","uri":"/ctad/#c11"},{"categories":["C++"],"content":"C++17 (CTAD) 编译器自动从类模板初始化值的类型推导出模板实参类型 std::pair p(2, 4.5) // 推导出std::pair\u003cint, double\u003e std::tuple t(4, 3, 2.5) // 等价于 auto t = std::make_tuple(4, 3, 2.5) new表达式同样适用： template\u003cclass T\u003e struct A { A(T){}; }; auto y = new A{1}; // 等价于 new A\u003cint\u003e(1); 同时支持聚合推导，因为我用的少就不多介绍了，记得初始化时用{}，而不是()就行了。 ","date":"2022-04-19","objectID":"/ctad/:3:0","series":null,"tags":["C++","编程技巧"],"title":"[C++技法] CTAD (since C++17)","uri":"/ctad/#c17-ctad"},{"categories":["C++"],"content":"用户定义的推导指引 除了靠编译器自动进行参数类型推导外，还可以自定义推导，语法结构类型声明lambda函数的返回类型 // explicit(可选) 模板名 (形参声明子句) -\u003e 简单模板标示; template\u003cclass T\u003e struct A { A(T) {}; template\u003cclass T\u003e A(T a, T b) {}; }; // 自定义推导，我这里让它变成了两个参数的构造函数全部推导为A\u003cint\u003e template\u003cclass T\u003e A(T, T)-\u003eA\u003cint\u003e; std::string str = \"hello\"; auto t = A(str, str); // 等价于 A\u003cint\u003e{}; ","date":"2022-04-19","objectID":"/ctad/:3:1","series":null,"tags":["C++","编程技巧"],"title":"[C++技法] CTAD (since C++17)","uri":"/ctad/#用户定义的推导指引"},{"categories":["C++"],"content":"其他 需要注意的是，CTAD只有在目标类型的构造函数使用模板参数的情况下才能进行推导。当然还有将某个类禁止CTAD的方法就不一一概述了。 ","date":"2022-04-19","objectID":"/ctad/:4:0","series":null,"tags":["C++","编程技巧"],"title":"[C++技法] CTAD (since C++17)","uri":"/ctad/#其他"},{"categories":["C++"],"content":"了解右值和右值引用的概念以及移动语义的实现。 右值引用(rvalue reference)，是C++11标准提出的一类数据类型。 可用于实现移动语义(move semantic)与完美转发(perfect forwarding)。 ","date":"2022-04-15","objectID":"/rvalueref/:0:0","series":null,"tags":["C++","编程技巧"],"title":"[C++技法] 右值引用与移动语义","uri":"/rvalueref/#"},{"categories":["C++"],"content":"右值 何为右值(r-value)，说人话就是只能放在等号右边的东西。例如int a = 1这个表达式中，a在等号左边，所以a是左值，而1是右值。 右值通常为一个表达式，是赋值计算产生临时生成的中间变量。 ","date":"2022-04-15","objectID":"/rvalueref/:1:0","series":null,"tags":["C++","编程技巧"],"title":"[C++技法] 右值引用与移动语义","uri":"/rvalueref/#右值"},{"categories":["C++"],"content":"右值引用 C++中，通常的引用是指左值引用，用符号\u0026表示，而右值引用符号为\u0026\u0026。 int a = 1; int\u0026 ref = a; // 左值引用 在上述代码中，定义了一个对a的左值引用，但是\u0026符号不能对1引用，int \u0026ref = 1的非法的。 但是可以使用int \u0026\u0026ref = 1，定义一个对1的右值引用。 int a = 1; int\u0026 ref = a; // 左值引用 // int\u0026 ref = 1; // error int\u0026\u0026 rref = 1; // 右值引用 // int\u0026\u0026 r_ref = a; // error，右值引用不可指向左值 rref = 2; // 右值引用也可以修改值 可以看出来这里的右值引用自身是一个左值（有名字的右值引用自身是左值）。 ","date":"2022-04-15","objectID":"/rvalueref/:2:0","series":null,"tags":["C++","编程技巧"],"title":"[C++技法] 右值引用与移动语义","uri":"/rvalueref/#右值引用"},{"categories":["C++"],"content":"std::move std::move一般理解为移动操作，在PImpl讲过的std::unique_ptr这个智能指针是禁止拷贝的，这是便可使用std::move对其进行移动操作。但std::move的原理是将左值转化为右值，底层操作中并没有实现内存的移动啥的。（如果没理解的话这就是个坑） int a = 1; int\u0026 ref = a; int\u0026\u0026 r_ref = std::move(a); // 将a转化为右值 与 int\u0026\u0026 rref = 1 等价 r_ref = 2; // 等价 a = 2 但是和int\u0026\u0026 rref = 1不同的是，此时r_ref也相当于a的一个左值引用。同时可以看出std::move根本没把a给移掉，因为像int这样的基本类型std::move对其是没有影响的。像string、std::unique_ptr这样的move就会变空了。要养成移动后不在使用的习惯 ","date":"2022-04-15","objectID":"/rvalueref/:2:1","series":null,"tags":["C++","编程技巧"],"title":"[C++技法] 右值引用与移动语义","uri":"/rvalueref/#stdmove"},{"categories":["C++"],"content":"右值引用作函数参数 void func(int \u0026\u0026v) { // do something } int a = 1; func(std::move(a)); // ok func(2); // ok 单从性能上来看，左右值引用都避免了传参拷贝。 顺带提一下，C++规定 \u0026\u0026 可以自动转化为const\u0026，所以当形参为void func(int const\u0026 v)时调用func(2)其实是隐含了一个转换。但右值引用比const引用更灵活，因为它还是可以修改的。 ","date":"2022-04-15","objectID":"/rvalueref/:2:2","series":null,"tags":["C++","编程技巧"],"title":"[C++技法] 右值引用与移动语义","uri":"/rvalueref/#右值引用作函数参数"},{"categories":["C++"],"content":"移动语义 ","date":"2022-04-15","objectID":"/rvalueref/:3:0","series":null,"tags":["C++","编程技巧"],"title":"[C++技法] 右值引用与移动语义","uri":"/rvalueref/#移动语义"},{"categories":["C++"],"content":"移动构造函数 在PImpl中也可以看到widget类中移动构造函数的参数为右值引用。 class widget { class impl; std::unique_ptr\u003cimpl\u003e pImpl; public: widget(); explicit widget(int); ~widget(); widget(widget\u0026\u0026); // 移动构造 widget(const widget\u0026) = delete; widget\u0026 operator=(widget\u0026\u0026); // 移动赋值 widget\u0026 operator=(const widget\u0026) = delete; }; int main() { widget w; widget wm = widget(std::move(w)); // do something } 这样做的好处同样是比用const引用更加灵活，可以做浅拷贝提升性能。 ","date":"2022-04-15","objectID":"/rvalueref/:3:1","series":null,"tags":["C++","编程技巧"],"title":"[C++技法] 右值引用与移动语义","uri":"/rvalueref/#移动构造函数"},{"categories":["C++"],"content":"容器避免深拷贝 STL类大都支持移动语义函数，比如vector就可以用std::move避免深拷贝以提升性能 std::vector\u003cstd::string\u003e sVec; std::string str = \"hello\"; sVec.push_back(std::move(str)); // 避免是对str的拷贝，性能得到提升 可移动对象在需要拷贝且被拷贝者之后不再被需要的场景，可以使用std::move触发移动语义，提升性能。 ","date":"2022-04-15","objectID":"/rvalueref/:3:2","series":null,"tags":["C++","编程技巧"],"title":"[C++技法] 右值引用与移动语义","uri":"/rvalueref/#容器避免深拷贝"},{"categories":["C++"],"content":"其他 ","date":"2022-04-15","objectID":"/rvalueref/:4:0","series":null,"tags":["C++","编程技巧"],"title":"[C++技法] 右值引用与移动语义","uri":"/rvalueref/#其他"},{"categories":["C++"],"content":"std::forward std::forward叫做完美转发，和std::move一样，这货跟转发没半毛钱关系。也是用于类型转换。 它不仅可以把左值转为右值，还可以反过来把右值转为左值。 使用方法： std::forward\u003cT\u003e(v); // 1. 当T为左值引用时，v被转换为T类型的左值引用 // 2. 否则，v转换为T类型的右值引用 这东西使用场景不多，我也不太懂，就不多做介绍了。 更多右值引用技巧可看这个 https://zhuanlan.zhihu.com/p/107445960 ","date":"2022-04-15","objectID":"/rvalueref/:4:1","series":null,"tags":["C++","编程技巧"],"title":"[C++技法] 右值引用与移动语义","uri":"/rvalueref/#stdforward"},{"categories":["C++"],"content":"“Pointer to implementation”, 指向实现的指针。将一个类的实现细节从其对象中移除，也是一种解耦方法。 ","date":"2022-04-14","objectID":"/pimpl/:0:0","series":null,"tags":["C++","编程技巧"],"title":"[C++技法] PImpl","uri":"/pimpl/#"},{"categories":["C++"],"content":"PImpl 使用私有的成员指针指向类的成员，是一种实现数据隐藏，最小化耦合和分离接口的现代C++编程技巧。 先看一段官方的PImpl代码 // interface (widget.h) class widget { // public members private: struct impl; std::unique_ptr\u003cimpl\u003e pImpl; }; // implementation (widget.cpp) struct widget::impl { // implementation details }; 可以看到widget类中使用了一个unique指针指向impl这个内部类。这样的好处主要有: ABI(Application Binary Interface, 二进制接口) 稳定，即不会打破二进制兼容。 降低编译依赖项，缩短编译时间。更改成员及实现时只需重新编译成员的源文件，而不需要重新编译所有使用了这个类的用户。 接口与实现分离，提高接口的稳定性。 降低耦合性。 将实现隐藏，头文件变得整洁。 主要缺点是性能会受点影响，因为成员都是用指针间接访问的。 ","date":"2022-04-14","objectID":"/pimpl/:0:0","series":null,"tags":["C++","编程技巧"],"title":"[C++技法] PImpl","uri":"/pimpl/#pimpl"},{"categories":["C++"],"content":"std::unique_ptr 可以看到上面的代码使用的std::unique_ptr这个智能指针。这是C++11中基于RAII(Resource acquisition is initialization)思想引入的一个智能指针。例如，定义指针p std::unique_ptr\u003cT\u003e p = std::make_unique\u003cT\u003e()，这时就不需要手动管理p指向的内存了，因为std::unique_ptr的析构函数会自动调用delete p。 需要注意的是 std::unique_ptr是禁止拷贝的，所以widget也无法使用拷贝构造函数，但可以使用移动构造函数。 ","date":"2022-04-14","objectID":"/pimpl/:1:0","series":null,"tags":["C++","编程技巧"],"title":"[C++技法] PImpl","uri":"/pimpl/#stdunique_ptr"},{"categories":["C++"],"content":"完善实现 因为类的定义中还有一个未实现的内部类，所以widget并不是一个完整的类，因此编译器不能为其自动生成构造和析构函数。此时需要在widget.cpp中显示的定义它的构造和析构函数，即使是使用=default也必须放在cpp中。 PImpl的完整代码： 引用自:en.cppreference.com/w/cpp/language/pimpl // interface (widget.hpp) #include \u003ciostream\u003e#include \u003cmemory\u003e class widget { class impl; std::unique_ptr\u003cimpl\u003e pImpl; public: widget(); explicit widget(int); ~widget(); widget(widget\u0026\u0026); // 移动构造 widget(const widget\u0026) = delete; widget\u0026 operator=(widget\u0026\u0026); // 移动赋值 widget\u0026 operator=(const widget\u0026) = delete; }; // --------------------------- // implementation (widget.cpp) // #include \"widget.hpp\" class widget::impl { int n; // private data public: impl(int n) : n(n) {} }; void widget::draw() const { pImpl-\u003edraw(*this); } void widget::draw() { pImpl-\u003edraw(*this); } widget::widget() = default; widget::widget(int n) : pImpl{std::make_unique\u003cimpl\u003e(n)} {} widget::widget(widget\u0026\u0026) = default; widget::~widget() = default; widget\u0026 widget::operator=(widget\u0026\u0026) = default; ","date":"2022-04-14","objectID":"/pimpl/:2:0","series":null,"tags":["C++","编程技巧"],"title":"[C++技法] PImpl","uri":"/pimpl/#完善实现"},{"categories":["C++"],"content":"其他 一般来说，工厂模式也能消除接口实现的编译时依赖，但工厂模式不是ABI稳定的，因为需要修改虚函数表。 PImpl类是对移动友好的；把大型的类重构为可以移动的PImpl，可以提升容器进行操作的算法性能，但也具有额外的运行时开销，因为任何在被移动对象上允许使用并需要访问私有实现的公开成员函数都必须进行空指针检查。 ","date":"2022-04-14","objectID":"/pimpl/:3:0","series":null,"tags":["C++","编程技巧"],"title":"[C++技法] PImpl","uri":"/pimpl/#其他"},{"categories":["杂记随想"],"content":"Course 6125021 Combinatorics Homework 1，武士数独 数独求解，第一个想到的方法就是DFS回溯。但是简单回溯法在求解单个数独时效率还能接受，放在五重数独（武士数独）上可以就有点差强人意了。我要是用它来解武士数独的话也没必要为这道题写篇博客了 🐱。 ","date":"2021-09-26","objectID":"/samurai-sudoku/:0:0","series":null,"tags":["数据结构","算法"],"title":"武士数独(五重数独) 舞蹈链解法","uri":"/samurai-sudoku/#"},{"categories":["杂记随想"],"content":"开搞 在此之前又仔细学习了一遍DancingLinks。DLX算法解数独的关键在于将数独转化为精确覆盖问题，这一步在单个矩阵的情况下还是比较容易的，但在武士数独上就比较繁琐了。 ","date":"2021-09-26","objectID":"/samurai-sudoku/:0:0","series":null,"tags":["数据结构","算法"],"title":"武士数独(五重数独) 舞蹈链解法","uri":"/samurai-sudoku/#开搞"},{"categories":["杂记随想"],"content":"定义数据结构 const static int SAMURAI_EDGE = 21; const static int SAMURAI_MATRIX = 441; const static int SAMURAI_ROWS = 405; const static int SUDOKU_EDGE = 9; const static int SUDOKU_MATRIX = 81; const static int COLUMN_SIZE = 1692; class DLNode { public: DLNode * Left; // 左结点 DLNode *Right; // 右结点 DLNode *Up; // 上结点 DLNode *Down; // 下结点 DLNode *Col; // 所属列结点 int row; // 行号 int nums; // 该列存在的结点个数（当结点为列结点时有效，否则为-1） DLNode(DLNode *Col, int n, int s = -1): Left(this), Right(this), Up(this), Down(this), Col(Col), row(n), nums(s){ if (Col) Col-\u003eAdd2Colume(this); }; ~DLNode() {}; void Add2Row(DLNode *node); // 添加结点到该行末尾 void Add2Colume(DLNode *node); // 添加结点到该列尾 void RemoveCol(); // 移除该结点所在的列 void RecoverCol(); // 还原列 void Remove(); // 移除该结点关联的行和列 }; class DancingLinks { public: DancingLinks(int s[SAMURAI_EDGE][SAMURAI_EDGE]); ~DancingLinks(); DLNode *Head; std::vector\u003cDLNode *\u003e Cols; // 列向量 std::vector\u003cDLNode *\u003e Ans; // 保存结果 bool DLX(); // DLX算法求解 void ShowResult(int result[SAMURAI_MATRIX]); // 输出结果 }; 数独规则: 每个格子只能填一个数字 每行每个数字只能填一遍(1-9) 每列每个数字只能填一遍(1-9) 每宫每个数字只能填一遍(1-9) ","date":"2021-09-26","objectID":"/samurai-sudoku/:1:0","series":null,"tags":["数据结构","算法"],"title":"武士数独(五重数独) 舞蹈链解法","uri":"/samurai-sudoku/#定义数据结构"},{"categories":["杂记随想"],"content":"武士数独精确覆盖问题 武士数独有五个数独组成，需要 $21 \\times 21$ 大小的矩阵存储数据，即 $441$ 个元素。给五个数独编号 武士数独编号点击放大 \" 武士数独编号 ","date":"2021-09-26","objectID":"/samurai-sudoku/:2:0","series":null,"tags":["数据结构","算法"],"title":"武士数独(五重数独) 舞蹈链解法","uri":"/samurai-sudoku/#武士数独精确覆盖问题"},{"categories":["杂记随想"],"content":"约束定义（索引从0开始） 定义441列 第0列：表示位置(0, 0)填了一个数字 第1列：表示位置(0, 1)填了一个数字 . . . . . . 第20列：表示位置(0, 20)填了一个数字 第21列：表示位置(1, 0)填了一个数字 . . . . . . 第440列：表示位置(20, 20)填了一个数字 位置$(X,Y)$, $Col = X \\times 21 + Y$ 定义405列（5个数独，总共45行） 第441列：0号数独的第0行填了数字1 第442列：0号数独的第0行填了数字2 . . . . . . 第449列：0号数独的第0行填了数字9 第450列：0号数独的第1行填了数字1 . . . . . . 第845列：4号数独的第8行填了数字9 第N列定义为 第$S$号数独$X$行填了数字$Y$，它们之间的关系为 $N = 441 + S \\times 81 + X \\times 9 + (Y-1)$ 定义405列（5个数独，总共45列） 第846列：0号数独的第0列填了数字1 第847列：0号数独的第0列填了数字2 . . . . . . 第857列：0号数独的第0列填了数字9 第858列：0号数独的第1列填了数字1 . . . . . . 第1250列：4号数独的第8列填了数字9 第N列定义为 第$S$号数独$X$列填了数字$Y$，它们之间的关系为 $N = 441 + 405 + S \\times 81 + X \\times 9 + (Y-1)$ 定义441列（$21\\times21$矩阵，总共49个宫,为方便计算没有删去空白的宫） 第1251列：第0宫填了数字1 第1252列：第0宫填了数字2 . . . . . . 第1259列：第0宫填了数字9 第1260列：第1宫填了数字1 . . . . . . 第1691列：第48宫填了数字9 第N列定义为 第$S$宫填了数字$D$,它们之间的关系为 $N = 441 + 405 + 405 + S \\times 9 + (D-1)$ 由上1692列完成了对武士数独的精确覆盖问题约束定义 ","date":"2021-09-26","objectID":"/samurai-sudoku/:3:0","series":null,"tags":["数据结构","算法"],"title":"武士数独(五重数独) 舞蹈链解法","uri":"/samurai-sudoku/#约束定义索引从0开始"},{"categories":["杂记随想"],"content":"初始化Dancing Links 用上图数独为例，(0, 0) 位置为 9，转换为DancingLinksz中的一行，则第0，449, 857, 1259列为 1 (即存在结点)，其余列为 0。 Dancing Links初始化 DancingLinks::DancingLinks(int sam[SAMURAI_EDGE][SAMURAI_EDGE]) { Head = new DLNode(nullptr, 0); // 创建列结点 1692个 for (int i = 0; i \u003c COLUMN_SIZE; i++) { auto t = new DLNode(nullptr, 0, 0); Head-\u003eAdd2Row(t); Cols.push_back(t); } std::vector\u003cDLNode *\u003e Rows; // 保存初始已存在数字的结点 for (int r = 0; r \u003c SAMURAI_EDGE; r++) { for (int c = 0; c \u003c SAMURAI_EDGE; c++) { for (int d = 0; d \u003c SUDOKU_EDGE; d++) { // 计算行数 int row = (r * SAMURAI_EDGE * SUDOKU_EDGE) + (c * SUDOKU_EDGE) + d; int sq = (c / 3) + ((r / 3) * 7); int t = VALID_SQUARE[sq]; if (t \u003e 0) { auto node = new DLNode(Cols[r * SAMURAI_EDGE + c], row); for (int i = 0; i \u003c 2; i++) { // 判断sq号宫属于第几号数独 int sd = (t \u003e 5 \u0026\u0026 !i) ? 4 : t-1; // 当前r，c属于sd号数独的几行几列 //（感觉用数组索引更方便， 一开始我是直接硬算行列，后来在网上看到有人用数组的方式实现） int sdr = SUDOKU_ROW[sd][r]; int sdc = SUDOKU_COLUMN[sd][c]; // 五个数独 总共45行 1-9数字情况 405列 node-\u003eAdd2Row(new DLNode(Cols[SAMURAI_MATRIX + (sd * SUDOKU_MATRIX) + (sdr * SUDOKU_EDGE) + d], row)); node-\u003eAdd2Row(new DLNode(Cols[SAMURAI_MATRIX + SAMURAI_ROWS + (sd * SUDOKU_MATRIX) + (sdc * SUDOKU_EDGE) + d], row)); if (t \u003c 6) i++; t -= 5; } node-\u003eAdd2Row(new DLNode(Cols[SAMURAI_MATRIX + SAMURAI_ROWS + SAMURAI_ROWS + (sq * SUDOKU_EDGE) + d], row)); if (sam[r][c] == (d + 1)) { Rows.push_back(node); } } } } } for (auto col = Head-\u003eRight; col != Head; col = col-\u003eRight) { if (!col-\u003enums) col-\u003eRemoveCol(); } for (auto iter = Rows.begin(); iter != Rows.end(); iter++) { (*iter)-\u003eRemove(); Ans.push_back(*iter); } } 算法执行过程 bool DancingLinks::DLX() { if (Head-\u003eRight == Head) { auto result = new int[Ans.size()]; for (int i = 0; i \u003c Ans.size(); i++) { result[i] = Ans[i]-\u003erow; } ShowResult(result); return true; } DLNode *col = nullptr; int min = INT_MAX; // 找到列元素最少的列 for (auto c = Head-\u003eRight; c != Head; c = c-\u003eRight) { if (min \u003e c-\u003enums) { col = c; min = c-\u003enums; } } col-\u003eRemoveCol(); for (auto node = col-\u003eDown; node != col; node = node-\u003eDown) { Ans.push_back(node); for (auto rnode = node-\u003eRight; rnode != node; rnode = rnode-\u003eRight) { rnode-\u003eCol-\u003eRemoveCol(); } if (DLX()) return true; for (auto lnode = node-\u003eLeft; lnode != node; lnode = lnode-\u003eLeft) { lnode-\u003eCol-\u003eRecoverCol(); } Ans.pop_back(); } col-\u003eRecoverCol(); return false; } ","date":"2021-09-26","objectID":"/samurai-sudoku/:3:1","series":null,"tags":["数据结构","算法"],"title":"武士数独(五重数独) 舞蹈链解法","uri":"/samurai-sudoku/#初始化dancing-links"},{"categories":["杂记随想"],"content":"结果输出 数独一： 武士数独1点击放大 \" 武士数独1 数独二： 武士数独2点击放大 \" 武士数独2 ","date":"2021-09-26","objectID":"/samurai-sudoku/:0:0","series":null,"tags":["数据结构","算法"],"title":"武士数独(五重数独) 舞蹈链解法","uri":"/samurai-sudoku/#结果输出"},{"categories":["杂记随想"],"content":"完整代码 https://github.com/xxy-im/SudokuNinja （代码持续优化中） ","date":"2021-09-26","objectID":"/samurai-sudoku/:0:0","series":null,"tags":["数据结构","算法"],"title":"武士数独(五重数独) 舞蹈链解法","uri":"/samurai-sudoku/#完整代码"},{"categories":["杂记随想"],"content":"小结 其本质虽然还是DFS回溯，但是在Dancing Links这一数据结构的加持下，回溯效率大大提升，求解时间小于0.1s，在内存暴增的年代，用些许内存的占用去换取运行时间的加速还是划算的。 后续计划在此基础上增加OCR功能，并优化代码使其适配任意形状数独 （没时间就算了）。 ","date":"2021-09-26","objectID":"/samurai-sudoku/:0:0","series":null,"tags":["数据结构","算法"],"title":"武士数独(五重数独) 舞蹈链解法","uri":"/samurai-sudoku/#小结"},{"categories":["杂记随想"],"content":"参考文章 https://en.wikipedia.org/wiki/Dancing_Links https://www.cnblogs.com/grenet/p/3163550.html https://www.acwing.com/solution/acwing/content/3843/ ","date":"2021-09-26","objectID":"/samurai-sudoku/:0:0","series":null,"tags":["数据结构","算法"],"title":"武士数独(五重数独) 舞蹈链解法","uri":"/samurai-sudoku/#参考文章"},{"categories":["杂记随想"],"content":"计算机程序设计艺术，第四卷第五册C，Dancing Links(舞蹈链算法) Dancing Links (舞蹈链)，是大名鼎鼎的 高德纳(Donald Knuth) 为快速实现他提出的X算法所提出的一种数据结构，所以也叫做 DLX算法，其目的是用于解决 精确覆盖问题。 ","date":"2021-09-22","objectID":"/dancinglinks/:0:0","series":null,"tags":["数据结构","算法"],"title":"Dancing Links (DLX 算法)学习笔记","uri":"/dancinglinks/#"},{"categories":["杂记随想"],"content":"覆盖问题 集合$S = \\lbrace1, 2, 3, 4, 5, 6, 7\\rbrace$，有其子集 $S_1 = \\lbrace3, 5\\rbrace$ $S_2 = \\lbrace1, 4, 7\\rbrace$ $S_3 = \\lbrace2, 3, 6\\rbrace$ $S_4 = \\lbrace1, 4, 6\\rbrace$ $S_5 = \\lbrace2, 7\\rbrace$ $S_6 = \\lbrace4, 5, 7\\rbrace$ 选择一些子集组成集合 $T$ ，使得 $T$ 中的包含的元素能覆盖集合 $S$ ，即 $S$ 中的所有元素都能在 $T$ 中找到包含它的子集（$\\forall x \\in S \\rightarrow \\forall x \\in T$）。 重复覆盖： 集合 $S$ 中的任意成员 $x$ 允许同时属于两个以上的子集，例如 $T=\\lbrace S_1, S_2, S_3\\rbrace$ 重复覆盖S。 精确覆盖： 集合 $S$ 中的任意成员 $x$ 属于且只属于 $T$ 中的一个子集，例如 $T=\\lbrace S_1, S_4, S_5\\rbrace$ 精确覆盖S。 用矩阵表示上述问题： 算法步骤如下： 如果矩阵 $A$ 为空且所有列都被选中，则当前局部解即为问题的一个解，返回成功；否则继续。 根据一定方法选择第 $c$ 列。如果某一列中没有1，则返回失败，并去除当前局部解中最新加入的行。 选择第 $r$ 行，使得 $A_{(r,c)} = 1$（该步是不确定的）。 将第 $r$ 行加入当前局部解中。 对于满足 $A_{(r,j)} = 1$ 的每一列 $j$，从矩阵 $A$ 中删除所有满足$A_{(i,j)} = 1$的行，最后再删除第 $j$ 列。 对所得比 $A$ 小的新矩阵递归地执行此算法。 $$ %S = % \\begin{pmatrix} % 0 \u0026 0 \u0026 1 \u0026 0 \u0026 1 \u0026 0 \u0026 0\\\\ % 1 \u0026 0 \u0026 0 \u0026 1 \u0026 0 \u0026 0 \u0026 1\\\\ % 0 \u0026 1 \u0026 1 \u0026 0 \u0026 0 \u0026 1 \u0026 0\\\\ % 1 \u0026 0 \u0026 0 \u0026 1 \u0026 0 \u0026 1 \u0026 0\\\\ % 0 \u0026 1 \u0026 0 \u0026 0 \u0026 0 \u0026 0 \u0026 1\\\\ % 0 \u0026 0 \u0026 0 \u0026 1 \u0026 1 \u0026 0 \u0026 1\\\\ % \\end{pmatrix} $$ 即选出矩阵的若干行，使得其中的1在所有列中出现且仅出现一次 $$ \\begin{array}{|c|c|c|c|c|c|c|c|} \\hline \u0026 \\mathbf{1} \u0026 \\mathbf{2} \u0026 \\mathbf{3} \u0026 \\mathbf{4} \u0026 \\mathbf{5} \u0026 \\mathbf{6} \u0026 \\mathbf{7}\\\\ \\hline \\mathbf{\\textcolor{blue}{S_1}} \u0026 \\textcolor{blue}{0} \u0026 \\textcolor{blue}{0} \u0026 \\textcolor{blue}{1} \u0026 \\textcolor{blue}{0} \u0026 \\textcolor{blue}{1} \u0026 \\textcolor{blue}{0} \u0026 \\textcolor{blue}{0}\\\\ \\hline \\mathbf{S_2} \u0026 1 \u0026 0 \u0026 0 \u0026 1 \u0026 0 \u0026 0 \u0026 1\\\\ \\hline \\mathbf{S_3} \u0026 0 \u0026 1 \u0026 1 \u0026 0 \u0026 0 \u0026 1 \u0026 0\\\\ \\hline \\mathbf{\\textcolor{blue}{S_4}} \u0026 \\textcolor{blue}{1} \u0026 \\textcolor{blue}{0} \u0026 \\textcolor{blue}{0} \u0026 \\textcolor{blue}{1} \u0026 \\textcolor{blue}{0} \u0026 \\textcolor{blue}{1} \u0026 \\textcolor{blue}{0}\\\\ \\hline \\mathbf{\\textcolor{blue}{S_5}} \u0026 \\textcolor{blue}{0} \u0026 \\textcolor{blue}{1} \u0026 \\textcolor{blue}{0} \u0026 \\textcolor{blue}{0} \u0026 \\textcolor{blue}{0} \u0026 \\textcolor{blue}{0} \u0026 \\textcolor{blue}{1}\\\\ \\hline \\mathbf{S_6} \u0026 0 \u0026 0 \u0026 0 \u0026 1 \u0026 1 \u0026 0 \u0026 1\\\\ \\hline \\end{array} $$ 蓝色标记的三行($S_1, S_4, S_5$)，便是精确覆盖问题的解 $$ \\begin{array}{|c|c|c|c|c|c|c|c|} \\hline \u0026 \\mathbf{1} \u0026 \\mathbf{2} \u0026 \\mathbf{3} \u0026 \\mathbf{4} \u0026 \\mathbf{5} \u0026 \\mathbf{6} \u0026 \\mathbf{7}\\\\ \\hline \\mathbf{\\textcolor{blue}{S_1}} \u0026 \\textcolor{blue}{0} \u0026 \\textcolor{blue}{0} \u0026 \\fcolorbox{red}{aqua}{1} \u0026 \\textcolor{blue}{0} \u0026 \\fcolorbox{red}{aqua}{1} \u0026 \\textcolor{blue}{0} \u0026 \\textcolor{blue}{0}\\\\ \\mathbf{\\textcolor{blue}{S_4}} \u0026 \\fcolorbox{red}{aqua}{1} \u0026 \\textcolor{blue}{0} \u0026 \\textcolor{blue}{0} \u0026 \\fcolorbox{red}{aqua}{1} \u0026 \\textcolor{blue}{0} \u0026 \\fcolorbox{red}{aqua}{1} \u0026 \\textcolor{blue}{0}\\\\ \\mathbf{\\textcolor{blue}{S_5}} \u0026 \\textcolor{blue}{0} \u0026 \\fcolorbox{red}{aqua}{1} \u0026 \\textcolor{blue}{0} \u0026 \\textcolor{blue}{0} \u0026 \\textcolor{blue}{0} \u0026 \\textcolor{blue}{0} \u0026 \\fcolorbox{red}{aqua}{1}\\\\ \\hline \\end{array} $$ 肉眼很容易一眼看出答案，但是计算机需要具体的算法步骤才行。下面看看 X算法 是如何求解的。 ","date":"2021-09-22","objectID":"/dancinglinks/:0:0","series":null,"tags":["数据结构","算法"],"title":"Dancing Links (DLX 算法)学习笔记","uri":"/dancinglinks/#覆盖问题"},{"categories":["杂记随想"],"content":"X算法（DFS回溯） 初始状态： $$ \\begin{array}{|c|c|c|c|c|c|c|c|} \\hline \u0026 \\mathbf{1} \u0026 \\mathbf{2} \u0026 \\mathbf{3} \u0026 \\mathbf{4} \u0026 \\mathbf{5} \u0026 \\mathbf{6} \u0026 \\mathbf{7}\\\\ \\hline \\mathbf{S_1} \u0026 0 \u0026 0 \u0026 1 \u0026 0 \u0026 1 \u0026 0 \u0026 0\\\\ \\hline \\mathbf{S_2} \u0026 1 \u0026 0 \u0026 0 \u0026 1 \u0026 0 \u0026 0 \u0026 1\\\\ \\hline \\mathbf{S_3} \u0026 0 \u0026 1 \u0026 1 \u0026 0 \u0026 0 \u0026 1 \u0026 0\\\\ \\hline \\mathbf{S_4} \u0026 1 \u0026 0 \u0026 0 \u0026 1 \u0026 0 \u0026 1 \u0026 0\\\\ \\hline \\mathbf{S_5} \u0026 0 \u0026 1 \u0026 0 \u0026 0 \u0026 0 \u0026 0 \u0026 1\\\\ \\hline \\mathbf{S_6} \u0026 0 \u0026 0 \u0026 0 \u0026 1 \u0026 1 \u0026 0 \u0026 1\\\\ \\hline \\end{array} $$ 高德纳建议每次选取 1 最少的列 X算法的执行步骤如下： 第一步： 选取1最少的列，此时第1，2，3，5，6列1的个数都是2，选择第1列。第1列中 $S_2$ 和 $S_4$均为1，选择 $S_2$ 加入当前解。（$T=\\lbrace S_2\\rbrace$） $$ \\begin{array}{|c|c|c|c|c|c|c|c|} \\hline \u0026 \\mathbf{\\textcolor{blue}{1}} \u0026 \\mathbf{2} \u0026 \\mathbf{3} \u0026 \\mathbf{\\textcolor{blue}{4}} \u0026 \\mathbf{5} \u0026 \\mathbf{6} \u0026 \\mathbf{\\textcolor{blue}{7}}\\\\ \\hline \\mathbf{S_1} \u0026 0 \u0026 0 \u0026 1 \u0026 0 \u0026 1 \u0026 0 \u0026 0\\\\ \\hline \\mathbf{\\textcolor{blue}{S_2}} \u0026 \\textcolor{blue}{1} \u0026 0 \u0026 0 \u0026 \\textcolor{blue}{1} \u0026 0 \u0026 0 \u0026 \\textcolor{blue}{1}\\\\ \\hline \\mathbf{S_3} \u0026 0 \u0026 1 \u0026 1 \u0026 0 \u0026 0 \u0026 1 \u0026 0\\\\ \\hline \\mathbf{S_4} \u0026 1 \u0026 0 \u0026 0 \u0026 1 \u0026 0 \u0026 1 \u0026 0\\\\ \\hline \\mathbf{S_5} \u0026 0 \u0026 1 \u0026 0 \u0026 0 \u0026 0 \u0026 0 \u0026 1\\\\ \\hline \\mathbf{S_6} \u0026 0 \u0026 0 \u0026 0 \u0026 1 \u0026 1 \u0026 0 \u0026 1\\\\ \\hline \\end{array} $$ 第二步： 第1列中$S_2$行和$S_4$行为1，第4列中$S_2$，$S_4$和$S_6$行为1，第7列中$S_2$，$S_5$和$S_6$行为1。所以移除第1，4，7列和$S_2$，$S_4$，$S_5$，$S_6$行。 $$ \\begin{array}{|c|c|c|c|c|c|c|c|} \\hline \u0026 \\mathbf{\\textcolor{blue}{1}} \u0026 \\mathbf{2} \u0026 \\mathbf{3} \u0026 \\mathbf{\\textcolor{blue}{4}} \u0026 \\mathbf{5} \u0026 \\mathbf{6} \u0026 \\mathbf{\\textcolor{blue}{7}}\\\\ \\hline \\mathbf{S_1} \u0026 \\textcolor{blue}0 \u0026 0 \u0026 1 \u0026 \\textcolor{blue}0 \u0026 1 \u0026 0 \u0026 \\textcolor{blue}0\\\\ \\hline \\mathbf{\\textcolor{blue}{S_2}} \u0026 \\textcolor{blue}{1} \u0026 \\textcolor{blue}0 \u0026 \\textcolor{blue}0 \u0026 \\textcolor{blue}{1} \u0026 \\textcolor{blue}0 \u0026 \\textcolor{blue}0 \u0026 \\textcolor{blue}{1}\\\\ \\hline \\mathbf{S_3} \u0026 \\textcolor{blue}0 \u0026 1 \u0026 1 \u0026 \\textcolor{blue}0 \u0026 0 \u0026 1 \u0026 \\textcolor{blue}0\\\\ \\hline \\mathbf{\\textcolor{blue}{S_4}} \u0026 \\textcolor{blue}1 \u0026 \\textcolor{blue}0 \u0026 \\textcolor{blue}0 \u0026 \\textcolor{blue}1 \u0026 \\textcolor{blue}0 \u0026 \\textcolor{blue}1 \u0026 \\textcolor{blue}0\\\\ \\hline \\mathbf{\\textcolor{blue}{S_5}} \u0026 \\textcolor{blue}0 \u0026 \\textcolor{blue}1 \u0026 \\textcolor{blue}0 \u0026 \\textcolor{blue}0 \u0026 \\textcolor{blue}0 \u0026 \\textcolor{blue}0 \u0026 \\textcolor{blue}1\\\\ \\hline \\mathbf{\\textcolor{blue}{S_6}} \u0026 \\textcolor{blue}0 \u0026 \\textcolor{blue}0 \u0026 \\textcolor{blue}0 \u0026 \\textcolor{blue}1 \u0026 \\textcolor{blue}1 \u0026 \\textcolor{blue}0 \u0026 \\textcolor{blue}1\\\\ \\hline \\end{array} $$ 第三步： 此时只剩下了$S_1$和$S_3$行可选，矩阵非空，算法继续执行递归回到第一步，此时初始状态如下。 $$ \\begin{array}{|c|c|c|c|c|} \\hline \u0026 \\mathbf{2} \u0026 \\mathbf{3} \u0026 \\mathbf{5} \u0026 \\mathbf{6} \\\\ \\hline \\mathbf{S_1} \u0026 0 \u0026 1 \u0026 1 \u0026 0\\\\ \\hline \\mathbf{S_3} \u0026 1 \u0026 1 \u0026 0 \u0026 1\\\\ \\hline \\end{array} $$ 第一步： 此时第2，5，6列1的个数最少，选取第2列，即将对应的 $S_3$ 加入当前解。 （$T=\\lbrace S_2, S_3 \\rbrace$） $$ \\begin{array}{|c|c|c|c|c|} \\hline \u0026 \\mathbf{\\textcolor{blue}{2}} \u0026 \\mathbf{\\textcolor{blue}{3}}\u0026 \\mathbf{5} \u0026 \\mathbf{\\textcolor{blue}{6}} \\\\ \\hline \\mathbf{S_1} \u0026 0 \u0026 1 \u0026 1 \u0026 0\\\\ \\hline \\mathbf{\\textcolor{blue}{S_3}} \u0026 \\textcolor{blue}1 \u0026 \\textcolor{blue}1 \u0026 0 \u0026 \\textcolor{blue}1\\\\ \\hline \\end{array} $$ 第二步： 移除 $S_3$ 关联的行列。 $$ \\begin{array}{|c|c|c|c|c|} \\hline \u0026 \\mathbf{\\textcolor{blue}{2}} \u0026 \\mathbf{\\textcolor{blue}{3}} \u0026 \\mathbf{5} \u0026 \\mathbf{\\textcolor{blue}{6}} \\\\ \\hline \\mathbf{\\textcolor{blue}{S_1}} \u0026 \\textcolor{blue}0 \u0026 \\textcolor{blue}1 \u0026 \\textcolor{blue}1 \u0026 \\textcolor{blue}0\\\\ \\hline \\mathbf{\\textcolor{blue}{S_3}} \u0026 \\textcolor{blue}1 \u0026 \\textcolor{blue}1 \u0026 \\textcolor{blue}0 \u0026 \\textcolor{blue}1\\\\ \\hline \\end{array} $$ 第三步： 矩阵为空，但是第5列仍没被选择，所以求解失败，需要回溯到新的行加入解集之前一步，并作另一选择再次执行算法。 $$ \\begin{array}{|c|} \\hline \\mathbf{5}\\\\ \\hline \\end{array} $$ 回溯： $$ \\begin{array}{|c|c|c|c|c|} \\hline \u0026 \\mathbf{2} \u0026 \\mathbf{3} \u0026 \\mathbf{5} \u0026 \\mathbf{6} \\\\ \\hline \\mathbf{S_1} \u0026 0 \u0026 1 \u0026 1 \u0026 0\\\\ \\hline \\mathbf{S_3} \u0026 1 \u0026 1 \u0026 0 \u0026 1\\\\ \\hline \\end{array} $$ 第一步： 因为之前在这一步选择了 $S_3$，所以这次我们选择 $S_1$ 加入局部最优解，即（$T=\\lbrace S_1, S_2 \\rbrace$）。 $$ \\begin{array}{|c|c|c|c|c|} \\hline \u0026 \\mathbf{2} \u0026 \\mathbf{\\textcolor{blue}{3}} \u0026 \\mathbf{\\textcolor{blue}","date":"2021-09-22","objectID":"/dancinglinks/:0:0","series":null,"tags":["数据结构","算法"],"title":"Dancing Links (DLX 算法)学习笔记","uri":"/dancinglinks/#x算法dfs回溯"},{"categories":["杂记随想"],"content":"Dancing Links 上述回溯求解过程存在大量的缓存矩阵和回溯矩阵的过程。而简单DFS回溯在这些过程中需要不断的删除又创建矩阵，当递归深度过深时还有可能栈溢出。于是算法大师高德纳提出了DLX(Dancing Links X)算法，即使用 Dancing Links 这一数据结构实现X算法。使得整个回溯算法过程中只需要使用一个矩阵链。算法执行过程中，指针在数据之间跳跃着，就像精巧设计的舞蹈一样，故称之为 Dancing Links (舞蹈链)。 舞蹈链的核心是双向链表实现的，先来看看双向链表的删除和插入操作。 双向链表点击放大 \" 双向链表 双向链表中任一元素都能很容易得到它左右两边（Left和Right指针）的元素。 删除Col2： Col1.Right = Col3; Col3.Left = Col1; // delete Col2; 此时我们并没有真的将Col2删除，只是链表遍历不到它了 插入Col2： Col1.Right = Col2; Col3.Left = Col2; 可以看出上面删除和插入都是 $O(1)$ 的。仔细想想这两个操作是不是和算法过程中的缓存，回溯对应。所以我们可以用链表的删除和插入来代替回溯算法中的缓存和回溯过程，且不需要开辟新的内存空间。 ","date":"2021-09-22","objectID":"/dancinglinks/:0:0","series":null,"tags":["数据结构","算法"],"title":"Dancing Links (DLX 算法)学习笔记","uri":"/dancinglinks/#dancing-links"},{"categories":["杂记随想"],"content":"数据结构定义 Dancing Links使用的是十字交叉双向循坏列表，即每个结点除了 Left, Right 指针外还存在 Up, Down 指针。同时还有一个指针指向所在的列结点。还需要一个Head结点，当Head-\u003eRight == Head 为 true 时，求解结束。（Head 结点只有 Left, Right 两个有效指针） class DLNode { public: DLNode * Left; // 左结点 DLNode *Right; // 右结点 DLNode *Up; // 上结点 DLNode *Down; // 下结点 DLNode *Col; // 所属列结点 int row; // 行号 int nums; // 该列存在的结点个数（当结点为列结点时有效，否则为-1） DLNode(DLNode *Col, int n, int s = -1): Left(this), Right(this), Up(this), Down(this), Col(Col), row(n), nums(s){ if (Col) Col-\u003eAdd2Colume(this); }; ~DLNode() {}; void Add2Row(DLNode *node); // 添加结点到该行末尾 void Add2Colume(DLNode *node); // 添加结点到该列尾 void RemoveCol(); // 移除该结点所在的列 void RecoverCol(); // 还原列 void Remove(); // 移除该结点关联的行和列 }; class DancingLinks { public: DancingLinks(int s[M][N]); ~DancingLinks(); DLNode *Head; // 头结点 std::vector\u003cDLNode *\u003e Cols; // 列向量 std::vector\u003cDLNode *\u003e Ans; // 保存结果 bool DLX(); // DLX算法求解 void ShowResult(); // 输出结果 }; 根据前面的精确覆盖问题构建Dancing Links结构。 Dancing Links结构图点击放大 \" Dancing Links结构图 ","date":"2021-09-22","objectID":"/dancinglinks/:1:0","series":null,"tags":["数据结构","算法"],"title":"Dancing Links (DLX 算法)学习笔记","uri":"/dancinglinks/#数据结构定义"},{"categories":["杂记随想"],"content":"DLX算法求解过程 首先判断 Head-\u003eRight == Head，若为真，求解完成，输出结果。否则算法继续执行。执行过程与前面所述的X算法类似，因此不再赘述。 代码如下： // 初始化Dancing Links DancingLinks::DancingLinks(int s[M][N]) { Head = new DLNode(nullptr, 0); // N列，创建N个列结点 for (int i = 0; i \u003c N; i++) { auto t = new DLNode(nullptr, 0, 0); Head-\u003eAdd2Row(t); Cols.push_back(t); } for (int r = 0; r \u003c M; r++) { bool flag = false; DLNode *node = nullptr; for (int c = 0; c \u003c N; c++) { // 创建结点 if (s[r][c]) { // 该行的第一个结点 if (!flag) { node = new DLNode(Cols[c], r+1); flag = true; } node-\u003eAdd2Row(new DLNode(Cols[c], r+1)); } } } // 移除初始为空的列 for (auto col = Head-\u003eRight; col != Head; col = col-\u003eRight) { if (!col-\u003enums) col-\u003eRemoveCol(); } } // DLX算法 bool DancingLinks::DLX() { if (Head-\u003eRight == Head) { ShowResult(); return true; } DLNode *col = nullptr; int min = INT_MIN; // 找到列元素最少的列 for (auto c = Head-\u003eRight; c != Head; c = c-\u003eRight) { if (min \u003e c-\u003enums) { col = c; min = c-\u003enums; } } col-\u003eRemoveCol(); for (auto node = col-\u003eDown; node != col; node = node-\u003eDown) { Ans.push_back(node); for (auto rnode = node-\u003eRight; rnode != node; rnode = rnode-\u003eRight) { rnode-\u003eCol-\u003eRemoveCol(); } if (DLX()) return true; for (auto lnode = node-\u003eLeft; lnode != node; lnode = lnode-\u003eLeft) { lnode-\u003eCol-\u003eRecoverCol(); } Ans.pop_back(); } col-\u003eRecoverCol(); } 程序完整代码： https://github.com/xxy-im/DancingLinks ","date":"2021-09-22","objectID":"/dancinglinks/:2:0","series":null,"tags":["数据结构","算法"],"title":"Dancing Links (DLX 算法)学习笔记","uri":"/dancinglinks/#dlx算法求解过程"},{"categories":["杂记随想"],"content":"参考文章 https://en.wikipedia.org/wiki/Dancing_Links https://www.cnblogs.com/grenet/p/3163550.html ","date":"2021-09-22","objectID":"/dancinglinks/:0:0","series":null,"tags":["数据结构","算法"],"title":"Dancing Links (DLX 算法)学习笔记","uri":"/dancinglinks/#参考文章"},{"categories":["杂记随想"],"content":"这是一篇关于一道算法课课后作业解题过程的一些思考 最近开始上算法设计与分析课，课后老师布置了一道关于时间复杂度的编程题。题目应该是老师自己编的。说实话，时间复杂度这种东西以前从来没有重视过，只停留根据代码判断程序时间复杂度的阶段。所以一开始也觉得做这种题目真是浪费时间(当然现在好像也觉得这题目没什么卵用)。 题目如下： 为了简单，只考虑6种算法的时间复杂度类型，分别为O(n)，O(nlogn)，O(n^2)，O(n^3)，O(2^n)和O(n!)。现有大量运行结果，请你根据运行结果判断复杂度类型。 输入： 第一行：一个整数k，表明有k对运行数据（n, t），n为运行规模，t为运行时间，都是整数。 第二行：k个整数，为运行规模，整数（\u003c1000001），每个数据之间有一个空格 第三行：k个整数，为运行时间，整数（\u003c100000），每个数据之间有一个空格 重复这三行，直至k=0。 输出： 每个例子输出一个整数（1-6之间），占一行，1,2,3,4,5,6分别代表复杂度类型O(n)，O(nlogn)，O(n^2)，O(n^3)，O(2^n)和O(n!)。最后一个例子也有回车 输入实例: 4 8 10 11 9 0 375 4218 31 6 17 20 24 19 22 25 16 110 1703 47 406 3468 5 359999 431998 518397 300000 746491 31 47 47 31 78 0 输出示例: 6 5 2 ","date":"2021-09-16","objectID":"/time-complexity/:0:0","series":null,"tags":["算法","解题"],"title":"关于复杂度类型判断的some思考","uri":"/time-complexity/#"},{"categories":["杂记随想"],"content":"思考 ","date":"2021-09-16","objectID":"/time-complexity/:0:0","series":null,"tags":["算法","解题"],"title":"关于复杂度类型判断的some思考","uri":"/time-complexity/#思考"},{"categories":["杂记随想"],"content":"探索一： 第一眼看到题目的时候一边想着这什么鬼一边又觉得这题目还挺新颖的。首先想到的是从运行规模之间的差值和运行时间的比值这方面下手。感觉这也是很多同学一开始的思路，然后做着做着发现这样的做法好像不需要用到k组数据呀，不是两组就行了吗。不管了，先做下去吧。代码写完，用实例测一遍，emmmmmm… 没过，不管先去页面上run一次。好家伙，一组数据都没通过。 提交运行点击放大 \" 提交运行 ","date":"2021-09-16","objectID":"/time-complexity/:1:0","series":null,"tags":["算法","解题"],"title":"关于复杂度类型判断的some思考","uri":"/time-complexity/#探索一"},{"categories":["杂记随想"],"content":"探索二： 我真的太菜了，实在不行我做下假输出骗个分得了，老师应该不会查代码吧。说干就干…… What the FXXK! 假输出测试点击放大 \" 假输出测试 玩我呢，123456都试过了，就这就这？记得班群里有个同学过了一组数据，问他要了下他的代码，然后把他的输出分别写死123456，一样全都过不了。好吧，是后台有什么判断机制？ ","date":"2021-09-16","objectID":"/time-complexity/:2:0","series":null,"tags":["算法","解题"],"title":"关于复杂度类型判断的some思考","uri":"/time-complexity/#探索二"},{"categories":["杂记随想"],"content":"探索三： 取不了巧，只好老老实实coding了，又做了两三种基于探索一的变种算法，样例数据都最多只能过两组，提交运行依然是没有一组通过。真的生气了，总觉得是后台有问题。喝了瓶薄荷味苏打水冷静了会儿后，决定还是从探索一的方法种的根本问题着手，即使用k组数据的问题，上面说了探索一中是基于两组数据的差值或比值分析，根本没完全利用到k组数据。既然要用k组数据，那我们先把一组数据单独拎出来研究好了。 当我们知道一个程序的运行规模n，和程序运行时间，那我们是不是能得到它的单位运行时间(不知道这个说法对不对，可以理解为当n为1的运行时间)。当然不能单纯的t / n，应该用t去除以n对应的复杂度函数才行，当每组数据按照某个复杂度函数除出来的单位时间最相近就是它对应的复杂度。 单位运行时间我就用uTime表示吧。 用示例中的数据举例： 第一组数据： n = 8, t = 0; 按O(n)求uTime： t / n; 按O(nlogn)求uTime： t / (n*log(n)); 按O(n^2)求uTime： t / (n*n); 按O(n^3)求uTime： t / (n*n*n); 按O(2^n)求uTime： t / (pow(2, n)); 按O(n!)求uTime： t / n!; 输入的k组数据都按照这个算法求得uTime，然后比较6种复杂度对应的k个uTime，当k个uTime最接近时候对应的复杂度算法便是该输入对应的复杂度。这里我用的方差去算的k个uTime的接近程度。当然这里的方差算法被我改动了，因为不同算法输入的规模n的数量级相差太大了，所以算方差的时候做了一个类似Normalization的方法。 方差计算代码如下： // 计算方差 double Variance(vector\u003cdouble\u003e \u0026uTimes) { double sum = std::accumulate(std::begin(uTimes), std::end(uTimes), 0.0); double mean = sum / uTimes.size(); //均值 double accum = 0.0; std::for_each (std::begin(uTimes), std::end(uTimes), [\u0026](const double d) { accum += (d/mean-1)*(d/mean-1); // Normalization，不然不能相互比较 }); return sqrt(accum/(uTimes.size())); } ","date":"2021-09-16","objectID":"/time-complexity/:3:0","series":null,"tags":["算法","解题"],"title":"关于复杂度类型判断的some思考","uri":"/time-complexity/#探索三"},{"categories":["杂记随想"],"content":"AC 感觉探索三的思路没大问题了，但有一点，就是在n的数量级太大的时候2^n和n!根本没法算，所以示例数据前两个都是过了，第三个会崩。然后我又是先不管这个问题了，草草的把代码先写出来后就迫不及待的提交运行了。 ！！！又是一组都没通过！！！ 简直要爆粗口了，真的有理由怀疑后台有问题。反复的做实验，监视各个阶段的输出，觉得一切的很合理，但结果为什么就这么不合理呢。实在不知道怎么做了，就想着把O(2^n)和O(n!)的大规模输入问题先解决掉。这时想到了上一个作业，老师让我们编程输出这6个复杂度1s内能处理的最大规模N，O(2^n)和O(n!)在1s内能处理的问题规模都是很小的，都是两位数的数量级。于是我便想到一个trick，当n \u003e 30时，则不计算O(2^n)对应的uTime，同时把其对应的方差设成一个很大的值，例如10000这样。同理当n \u003e 30时,O(n!)对应的操作也做同样处理。 代码如下： int GetComplexity(map\u003cint, int\u003e \u0026nt) { vector\u003cdouble\u003e uTimes; // 记录不同复杂度对应的单位运行时间 vector\u003cdouble\u003e vars; // 记录6种复杂度对应uTime的方差 for (int i = 0; i \u003c 6; i++) { uTimes.clear(); bool flag = false; for (auto ntIter = nt.begin(); ntIter != nt.end(); ntIter++) { auto n = ntIter-\u003efirst; auto t = ntIter-\u003esecond; if ( i \u003e 3 \u0026\u0026 n \u003e 30) { flag = false; break; } uTimes.push_back(Fun[i](t, n)); } vars.push_back(!flag ? Variance(uTimes) : 10000); } auto min = min_element(begin(vars), end(vars)); return distance(begin(vars), min) + 1; // 返回最小方差的索引+1 } 为了方便实现探索一中的算法，所以用的std::map存储(n, t)，因为它能根据键值自动排序。后面也没有改过来，其实只用两个std::vector就可以了。 处理完后，我再提交，竟然就过了…就过了…过了…了…, 所以前面显示的未通过到底是什么? 是程序中断了吗? 还是什么神秘的控制机制。 喜大普奔点击放大 \" 喜大普奔 ","date":"2021-09-16","objectID":"/time-complexity/:4:0","series":null,"tags":["算法","解题"],"title":"关于复杂度类型判断的some思考","uri":"/time-complexity/#ac"},{"categories":["杂记随想"],"content":"完整代码 /* * @Author: xxy * @Date: 2021-09-16 16:41:37 * @Description: 复杂度判断 */ #include \u003ciostream\u003e#include \u003cvector\u003e#include \u003cmap\u003e#include \u003ccmath\u003e#include \u003cnumeric\u003e #include \u003calgorithm\u003e using namespace std; // 求阶乘 int Fn(int n) { int f; if (n == 0 || n == 1) f = 1; else f = Fn(n - 1) * n; return f; } // 计算方差 double Variance(vector\u003cdouble\u003e \u0026uTimes) { double sum = accumulate(begin(uTimes), end(uTimes), 0.0); double mean = sum / uTimes.size(); //均值 double accum = 0.0; for_each (begin(uTimes), end(uTimes), [\u0026](const double d) { accum += (d/mean-1)*(d/mean-1); // Normalization，不然不能相互比较 }); return sqrt(accum/(uTimes.size())); } // 求单位运行时间 double f0 (double t, int n) { return t / n; } // O(n) double f1 (double t, int n) { return (t / (n * log2(n))); } // O(nlogn) double f2 (double t, int n) { return (t / pow(n, 2)); } // O(n^2) double f3 (double t, int n) { return (t / pow(n, 3)); } // O(n^3) double f4 (double t, int n) { return (t / pow(2, n)); } // O(2^n) double f5 (double t, int n) { return (t / Fn(n)); } // O(n!) // 定义函数数组 double (*Fun[])(double t, int n) { f0, f1, f2, f3, f4, f5 }; int GetComplexity(map\u003cint, int\u003e \u0026nt) { vector\u003cdouble\u003e uTimes; // 记录不同复杂度对应的单位运行时间 vector\u003cdouble\u003e vars; // 记录6种复杂度对应uTime的方差 for (int i = 0; i \u003c 6; i++) { uTimes.clear(); bool flag = false; for (auto ntIter = nt.begin(); ntIter != nt.end(); ntIter++) { auto n = ntIter-\u003efirst; auto t = ntIter-\u003esecond; if ( i \u003e 3 \u0026\u0026 n \u003e 30) { flag = false; break; } uTimes.push_back(Fun[i](t, n)); } vars.push_back(!flag ? Variance(uTimes) : 10000); } auto min = min_element(begin(vars), end(vars)); return distance(begin(vars), min) + 1; // 返回最小方差的索引+1 } int main() { int k; int tmp; map\u003cint, int\u003e ntMap; while (cin \u003e\u003e k \u0026\u0026 k) { vector\u003cint\u003e nVec; vector\u003cint\u003e tVec; ntMap.clear(); for (int i = 0; i \u003c k; i++) { cin \u003e\u003e tmp; nVec.push_back(tmp); } for (int i = 0; i \u003c k; i++) { cin \u003e\u003e tmp; tVec.push_back(tmp); } for (int i = 0; i \u003c k; i++) { ntMap[nVec[i]] = tVec[i]; } cout \u003c\u003c GetComplexity(ntMap) \u003c\u003c endl; } return 0; } ","date":"2021-09-16","objectID":"/time-complexity/:0:0","series":null,"tags":["算法","解题"],"title":"关于复杂度类型判断的some思考","uri":"/time-complexity/#完整代码"},{"categories":["杂记随想"],"content":"小结 题目做完了，好像学到了点什么，又好像什么都没学到。总觉得这道题目但凡有一点意义也不至于一点意义也没有。 ","date":"2021-09-16","objectID":"/time-complexity/:0:0","series":null,"tags":["算法","解题"],"title":"关于复杂度类型判断的some思考","uri":"/time-complexity/#小结"},{"categories":["iOS"],"content":"手上有个很老的项目对应的苹果包需要在xcode上做些修改，苦于买不起Mac，只好出此下策 现在后悔去年买的那台2070显卡的笔记本了，就很后悔，为什么不买mac 好在家里的PC配置还可以，所以就想到用虚拟机来玩玩 ","date":"2021-06-10","objectID":"/vm-macos/:0:0","series":null,"tags":["虚拟机","iOS","MacOS","XCode"],"title":"虚拟机下的iOS开发(MacOS + XCode)","uri":"/vm-macos/#"},{"categories":["iOS"],"content":"安装VM Player 虚拟机我选的是VMware Workstation Player, 注意后面这个player 个人用户用player就行了, 和Workstation相比, player免费, 体积小, 够用 直接到官网下载就行 ","date":"2021-06-10","objectID":"/vm-macos/:1:0","series":null,"tags":["虚拟机","iOS","MacOS","XCode"],"title":"虚拟机下的iOS开发(MacOS + XCode)","uri":"/vm-macos/#安装vm-player"},{"categories":["iOS"],"content":"给VM打上MacOS补丁 距离我上一次用虚拟机装MacOS可能有八九年那么久了, 装完VM后才发现虚拟机的系统选项里已经没有Mac这个选项了, 网上查到需要通过补丁来解锁这个选项 这里使用Auto Unlocker解锁 软件直接放这了 链接: https://pan.baidu.com/s/1SS0VCgJo9Ey1LjjTh2aqkw 提取码: ajwo 软件转载于ypojie 下完解压直接unlock然后等待完成就行了 完成后创建虚拟机的时候选骚后安装操作系统, 下一步后就可以选择Apple Mac OS了, 版本默认就行, 没多大关系 创建虚拟机点击放大 \" 创建虚拟机 磁盘选项点击放大 \" 磁盘选项 磁盘大小这里有个坑, 建议80gb, 我这里选了60为后面安装XCode埋下了个大坑 最后虚拟机设置里把下载来的MacOS的IOS镜像放到虚拟机驱动器里就可以了 这是我用的镜像 链接: https://pan.baidu.com/s/18zXlfSU6OkaifQ-aHeQVtQ 提取码: 8ilm 配置完这些后启动虚拟就可以开始安装MacOS了 系统安装成功点击放大 \" 系统安装成功 ","date":"2021-06-10","objectID":"/vm-macos/:1:1","series":null,"tags":["虚拟机","iOS","MacOS","XCode"],"title":"虚拟机下的iOS开发(MacOS + XCode)","uri":"/vm-macos/#给vm打上macos补丁"},{"categories":["iOS"],"content":"安装XCode 前面有说到磁盘大小会给安装XCode埋坑 因为我安装完系统后没有第一时间安装XCode, 我先装了些常用的软件, 反正装完一些软件后是还有40GB的磁盘空间, 然后我直接在app store上安装XCode, 下载完成后安装的过程中提示安装失败了, 我再点下载提示可用磁盘空间不足, 无法安装此产品 XCode下载的大小才11个多G, 用了网上的删除Time Machine的方法也没用, 因为我系统确实是只有40GB空闲 搞不懂为什么需要那么多空间安装, 于是想通过下载xip文件的方式来安装 下载地址是 https://developer.apple.com/download/all/?q=xcode 我下的是12.5版本 网页下载xcode点击放大 \" 网页下载xcode 下载完后点击安装还是报磁盘空间不足 无语… 果断关掉虚拟机, 打开虚拟机设置, 将磁盘扩展至80GB, 扩展需要花点时间 ","date":"2021-06-10","objectID":"/vm-macos/:2:0","series":null,"tags":["虚拟机","iOS","MacOS","XCode"],"title":"虚拟机下的iOS开发(MacOS + XCode)","uri":"/vm-macos/#安装xcode"},{"categories":["iOS"],"content":"虚拟机磁盘空间扩展 扩展完成后并不是Mac里也会同步分区好, 需要手动给系统分区扩容, 因为虚拟机的硬盘变大后系统的分区表信息并不会变 Mac中打开终端输入 diskutil list 可以看到现在是磁盘信息, 比如图片中可以看到我的磁盘总空间是85.9GB但是Apple_APFS(disk0s2)只用了64.2GB, 还有21.5GB的free 系统扩容前点击放大 \" 系统扩容前 现在需要将disk0s2(每个人的数字可能不一样)扩容, 因为是APFS格式, 所以用resizeContainer命令 diskutil apfs resizeContainer disk0s2 85.6GB 命令执行成功后可以看到扩展的21.5GB也全都加到disk0s2中了 系统扩容后点击放大 \" 系统扩容后 这时候再安装XCode就ok了, xip解压出来是29.6GB左右, 加上xip本身是11.几GB, 所以应该至少要有42GB左右的空闲空间才够 安装成功点击放大 \" 安装成功 ","date":"2021-06-10","objectID":"/vm-macos/:2:1","series":null,"tags":["虚拟机","iOS","MacOS","XCode"],"title":"虚拟机下的iOS开发(MacOS + XCode)","uri":"/vm-macos/#虚拟机磁盘空间扩展"},{"categories":["iOS"],"content":"小结 这是一段因为穷而导致的莫名奇妙的经历[doge] ","date":"2021-06-10","objectID":"/vm-macos/:3:0","series":null,"tags":["虚拟机","iOS","MacOS","XCode"],"title":"虚拟机下的iOS开发(MacOS + XCode)","uri":"/vm-macos/#小结"},{"categories":["Linux"],"content":"前几天装了WSL，身为多年的伪Vim粉VS Code宇宙第一决定顺便把Vim给搞搞 本来是打算就用原生Vim然后堆plug的，但是既然已经折腾了，就不差这一下了。 ","date":"2021-02-18","objectID":"/neovim/:0:0","series":null,"tags":["Vim","Linux"],"title":"Ubuntu下安装Neovim+SpaceVim","uri":"/neovim/#"},{"categories":["Linux"],"content":"安装Neovim 因为太久没玩过Ubuntu了，所以上来就是sudo apt install neovim，然后报Error，提示 Unable to locate package neovim 进Neovim官网看了下安装教程，在Ubuntu那一栏可以看到，从18.04开始可以通过PPA来安装了，照着官方教程一顿梭 sudo add-apt-repository ppa:neovim-ppa/stable sudo apt-get update sudo apt-get install neovim 老版本的Ubuntu可能需要先安装PPA sudo apt-get install software-properties-common 安装完后可以输入nvim 打开，当然可以修改下alias，通过vi打开nvim 这里我选择软连接的方式将vi连接到nvim，因为现在wsl系统里的vi和vim命令就是软连接文件，所以我想删掉现在的vi，然后重新软连接到nvim 先which vi 找到vi的目录， 比如我的系统中vi文件的目录是/usr/bin/ 再输入ls -il 可以看到vi是个连接文件，指向 /etc/alternatives/vi 然后这里我把两个软连接给删掉再建立新的软连接 sudo rm -rf /usr/bin/vi sudo rm -rf /usr/bin/vim sudo ln -s /usr/bin/nvim /usr/bin/vi sudo ln -s /usr/bin/nvim /usr/bin/vim 这时候再输入vi/vim就可以打开nvim了 Neovim点击放大 \" Neovim ","date":"2021-02-18","objectID":"/neovim/:1:0","series":null,"tags":["Vim","Linux"],"title":"Ubuntu下安装Neovim+SpaceVim","uri":"/neovim/#安装neovim"},{"categories":["Linux"],"content":"安装SpaceVim SpaceVim是一个开源的模块化配置集合，可以通过它很方便的打造出适用于各种开发场景的IDE。 curl -sLf https://spacevim.org/cn/install.sh | bash 安装SpaceVim点击放大 \" 安装SpaceVim 字体安装报错点击放大 \" 字体安装报错 提示安装完成，打开vim却没有加载出SpaceVim，不知道哪里出现问题，往上翻也只看到几个字体安装的报错，感觉应该是和WSL环境的配置文件有关系，但还是先在网上找了那几个字体报错的解决方法 # 使mkfontscale和mkfontdir命令正常运行 sudo apt-get install ttf-mscorefonts-installer # 使fc-cache命令正常运行 sudo apt-get install fontconfig 然后再安装试试 结果还真是字体的问题，重装下就好了… SpaceVim点击放大 \" SpaceVim Normal模式下:SPUpdate 更新所有插件，:SPUpdate SpaceVim可以更新自身 更新所有插件点击放大 \" 更新所有插件 再次打开vim又 vimproc’s DLL报错，直接:VimProcInstall 或者make一下 cd ~/.SpaceVim/bundle/vimproc.vim/ make 有些icon显示不出来，只有个小方框，有可能是因为字体的问题 可以使用fc-list命令查看ubuntu中安装的字体 SpaceVim默认使用SourceCodePro Nerd Font Mono字体 安装Nerd Font wget -c https://github.com/ryanoasis/nerd-fonts/releases/download/v2.1.0/SourceCodePro.zip sudo unzip SourceCodePro -d /usr/share/fonts/SourceCodePro cd /usr/share/fonts/SourceCodePro sudo mkfontscale # 生成核心字体信息 sudo mkfontdir # 生成字体文件夹 sudo fc-cache -fv # 刷新系统字体缓存 如果使用终端的话需要修改终端的配置 比如我用的是Windows Terminal 在Windows下安装完SourceCodePro Nerd Font Mono字体后需要在Windows Terminal配置文件WSL配置下加上 \"fontFace\": \"SauceCodePro Nerd Font\" 注意第一个f小写，然后再重启终端就能看到图标都出来了 更新字体后点击放大 \" 更新字体后 ","date":"2021-02-18","objectID":"/neovim/:2:0","series":null,"tags":["Vim","Linux"],"title":"Ubuntu下安装Neovim+SpaceVim","uri":"/neovim/#安装spacevim"},{"categories":["Linux"],"content":"一些简单的配置 ","date":"2021-02-18","objectID":"/neovim/:3:0","series":null,"tags":["Vim","Linux"],"title":"Ubuntu下安装Neovim+SpaceVim","uri":"/neovim/#一些简单的配置"},{"categories":["Linux"],"content":"相对行号 看不习惯相对行号，在配置文件中取消 relativenumber = false ","date":"2021-02-18","objectID":"/neovim/:3:1","series":null,"tags":["Vim","Linux"],"title":"Ubuntu下安装Neovim+SpaceVim","uri":"/neovim/#相对行号"},{"categories":["Linux"],"content":"主题 打开~/.SpaceVim.d/init.toml 主题选择 SpaceVim colorscheme = \"SpaceVim\" SpaceVim主题点击放大 \" SpaceVim主题 ","date":"2021-02-18","objectID":"/neovim/:3:2","series":null,"tags":["Vim","Linux"],"title":"Ubuntu下安装Neovim+SpaceVim","uri":"/neovim/#主题"},{"categories":["Linux"],"content":"C++ 打开vim，空格 + f + v + d (一个个按)，快捷键打开配置文件，空格(space)为自定义快捷键的前缀，按下空格后可以看到所有的自定义快捷键 按照官方配置把需要的加上去就可以了 像clangd，clang这些如果需要的话要先装好才能配置成功，不然vim会报clangd is not executable 直接apt安装的clang貌似版本会有点低，所以建议用官方源 bash -c \"$(wget -O - https://apt.llvm.org/llvm.sh)\" 在/usr/bin 目录下找到你的clangd安装目录，比如我的是/usr/bin/clangd-11 再执行下面命令 sudo update-alternatives --install /usr/bin/clangd clangd /usr/bin/clangd-11 100 SpaceVim默认使用的补全插件是deoplete，愿意折腾的同学也可以改成YCM，注意兼容问题 最后在cpp文件中使用SPC + l + r就可以run代码了 修改编译命令可参考Custom Task ","date":"2021-02-18","objectID":"/neovim/:3:3","series":null,"tags":["Vim","Linux"],"title":"Ubuntu下安装Neovim+SpaceVim","uri":"/neovim/#c"},{"categories":["Linux"],"content":"Python 官方文档 ","date":"2021-02-18","objectID":"/neovim/:3:4","series":null,"tags":["Vim","Linux"],"title":"Ubuntu下安装Neovim+SpaceVim","uri":"/neovim/#python"},{"categories":["Linux"],"content":"小结 其实VS Code + Remote一套用起来才更虚服。 所以上面这些都是瞎折腾，桌面党还是继续老老实实用VS Code ","date":"2021-02-18","objectID":"/neovim/:4:0","series":null,"tags":["Vim","Linux"],"title":"Ubuntu下安装Neovim+SpaceVim","uri":"/neovim/#小结"},{"categories":null,"content":"最近需要在Linux下跑写些小程序，但是平时更多时候都离不开Windows打游戏。所以打算使用Win下的Linux子系统 ","date":"2021-02-09","objectID":"/wsl/:0:0","series":null,"tags":null,"title":"Windows下运行Linux的正确姿势","uri":"/wsl/#"},{"categories":null,"content":"启动WSL功能 首先在控制面板的打开或启动Windows程序中将Linux子系统功能勾选上，点确认后会提示重启计算机 控制面板-\u003e程序-\u003e启动或关闭Windows功能点击放大 \" 控制面板-程序-启动或关闭Windows功能 ","date":"2021-02-09","objectID":"/wsl/:1:0","series":null,"tags":null,"title":"Windows下运行Linux的正确姿势","uri":"/wsl/#启动wsl功能"},{"categories":null,"content":"安装Linux子系统 这里我选择了一个最方便直接的方法，在Windows商店下载安装，直接在商店搜索WSL，Ubuntu，或者Linux就能找到，比如我安装的是Ubuntu 20.04 安装Ubuntu子系统点击放大 \" 安装Ubuntu子系统 安装完成打开后输入用户名密码就可以使用了。 现在最新的WSL2是可以支持GPU的，所有一些跑Deep的小伙伴可以试试，可以在Windows命令行中输入如下命令查看当前的WSL版本，因为我不需要用到子系统的GPU，所有我没有升级到WSL2，有需要的可以自行找下教程 wsl --list -v 如果没有Windows商店没有满足你要求的Linux子系统，网上貌似也有教程教你运行各种不同的Linux子系统。 ","date":"2021-02-09","objectID":"/wsl/:2:0","series":null,"tags":null,"title":"Windows下运行Linux的正确姿势","uri":"/wsl/#安装linux子系统"},{"categories":null,"content":"文件共享 ","date":"2021-02-09","objectID":"/wsl/:3:0","series":null,"tags":null,"title":"Windows下运行Linux的正确姿势","uri":"/wsl/#文件共享"},{"categories":null,"content":"子系统访问Windows 在子系统的bash中cd /mnt可以看到Windows下的磁盘已经被挂载到子系统下，可以直接copy需要的文件到子系统中 ","date":"2021-02-09","objectID":"/wsl/:3:1","series":null,"tags":null,"title":"Windows下运行Linux的正确姿势","uri":"/wsl/#子系统访问windows"},{"categories":null,"content":"Windows访问子系统文件 子系统的磁盘空间对应Windows下的存储目录默认是在C:\\Users\\用户名\\AppData\\Local\\Packages\\CanonicalGroupLimited.Ubuntu20.04onWindows_79rhkp1fndgsc(这里改为自己的目录)\\LocalState\\rootfs ","date":"2021-02-09","objectID":"/wsl/:3:2","series":null,"tags":null,"title":"Windows下运行Linux的正确姿势","uri":"/wsl/#windows访问子系统文件"},{"categories":null,"content":"关于子系统桌面安装 这部分没内容，因为我并不推荐为Linux子系统安装桌面环境。 ","date":"2021-02-09","objectID":"/wsl/:4:0","series":null,"tags":null,"title":"Windows下运行Linux的正确姿势","uri":"/wsl/#关于子系统桌面安装"},{"categories":null,"content":"小结 后续使用过程中当然还会遇到许多坑，毕竟还有很多地方不成熟，比如使用ssh的时候可能会有端口占用问题，Windows访问子系统的权限问题等等。但是相对虚拟机来说，确实方便和实用许多，从系统功能完整性来说，个人认为是在虚拟机之下，Cygwin之上，毕竟Cygwin只是假装自己是个Linux，而WSL是实实在在的用Windows API实现Linux，对于用户层来说就是是实在在的Linux。 ","date":"2021-02-09","objectID":"/wsl/:5:0","series":null,"tags":null,"title":"Windows下运行Linux的正确姿势","uri":"/wsl/#小结"},{"categories":["深度学习"],"content":"在这个万物皆可CS的时代，程序猿如果不学点机器学习/深度学习知识，仿佛都有点跟不上潮流了 随着近几年人工智能的热潮，AI，AlphaGo，大数据，数据挖掘，机器学习这些词汇在互联网中随处可见。人脸识别，语音助手，美颜拍照，APP广告推送，甚至大数据杀熟这些技术的背后究竟是人性的泯灭，还是道德的沦丧… 咳咳… 回到正题，先来看看人工智能，机器学习，深度学习三者的关系 三者关系点击放大 \" 三者关系 ","date":"2020-01-28","objectID":"/ml/:0:0","series":null,"tags":["人工智能","机器学习"],"title":"机器学习初体验","uri":"/ml/#"},{"categories":["深度学习"],"content":"人工智能(AI) 一个笼统的概念，简单描述一门让机器好似有人类智慧的计算机学科。人工智能可以对人的意识、思维的信息过程的模拟。人工智能不是人的智能，但能像人那样思考、也可能超过人的智能。 ","date":"2020-01-28","objectID":"/ml/:0:0","series":null,"tags":["人工智能","机器学习"],"title":"机器学习初体验","uri":"/ml/#人工智能ai"},{"categories":["深度学习"],"content":"机器学习(Machine Learning) 顾名思义是一种让计算机自己学习的算法。在智能应用开发的早期，许多系统都是使用大量的if-else结构来进行决策和处理数据的，比如希望判断邮件是否为垃圾邮件，可能需要先创建一个类似敏感词库的东西，然后判断邮件的内容是否包含这些关键词，if包含则为垃圾邮件，else不是垃圾邮件。这样的系统在某些领域确实是非常简单且高效的，尤其在一些系统所有的输入和输出都是能够被人们掌握的情况下。但是这种靠if-else的人为决策，明显很难对任务的变化进行自适应，且在开发系统时需对该系统将要处理的各种场景了如指掌。就像你很难用if-else来写一个人脸检测系统。 成功的机器学习算法是能够将决策过程自动化的那些算法，而这些决策过程是通过大量的数据输入(即已知的示例)中泛化得出的。 通常任何问题都可以用 $y=f(x)$ 模型或概率模型$P(Y|X)$ 表示，而机器学习的最终结果就是求出这个决策函数 $f(x)$ 或条件概率分布 $P(Y|X)$ ","date":"2020-01-28","objectID":"/ml/:0:0","series":null,"tags":["人工智能","机器学习"],"title":"机器学习初体验","uri":"/ml/#机器学习machine-learning"},{"categories":["深度学习"],"content":"基本概念 ","date":"2020-01-28","objectID":"/ml/:0:0","series":null,"tags":["人工智能","机器学习"],"title":"机器学习初体验","uri":"/ml/#基本概念"},{"categories":["深度学习"],"content":"样本数据 上面说到机器学习最终目的是求出 $y=f(x)$ 这个模型，样本数据便是一些已知的 $(x, y)$ 或者只有 $x$。其中 $x$ 叫做输入数据，$y$ 叫做输出数据（或者叫标签、标注）。$x$ 和 $y$可以是多维的可以包含多个特征。例如输入实例$x$的特征向量记作 $$ x= (x^{(1)}, x^{(2)}, x^{(3)}, \\ldots, x^{(i)}, \\ldots, x^{(n)})^T $$ $x^{(1)}$ 表示 $x$ 的第 $i$ 个特征。而 $x_i$表示多个输入中的第i个输入，即 $$ x_i = (x_{i}^{(1)}, x_{i}^{(2)}, x_{i}^{(3)}, \\ldots, x_{i}^{(n)}) $$ ","date":"2020-01-28","objectID":"/ml/:1:0","series":null,"tags":["人工智能","机器学习"],"title":"机器学习初体验","uri":"/ml/#样本数据"},{"categories":["深度学习"],"content":"数据集 完整的数据集表示为 $T = \\lbrace(x_1, y_1), (x_2, y_2), (x_3, y_3), \\ldots, (x_n, y_n)\\rbrace$，并不是所有的数据都将用于模型训练，通常数据集会被分为三个部分：训练集、验证集、测试集 训练集：用于训练学习模型，通常比例不低于总数据量的50% 验证集：用于衡量训练过程中模型的好坏，通过不断迭代来优化模型 测试集：验证集智能用于监视和辅助模型训练，不能用来代表模型的好坏，哪怕验证的准确率是100%测试集也有可能是10%的准确率，这时的模型也是不能被接受的 ","date":"2020-01-28","objectID":"/ml/:2:0","series":null,"tags":["人工智能","机器学习"],"title":"机器学习初体验","uri":"/ml/#数据集"},{"categories":["深度学习"],"content":"特征 特征是机器学习和模式识别领域一个比较特有的名词，在传统机器学习算法中，由于计算性能和参数的限制，所以输入的数据维数不能太高。我们手机随随便便一张照片就有几个MB的数据量，可能会有几百万个像素，这么高维的数据量我们是不能直接输入给学习机的，因此我们需要针对特别的应用提取相对应的特征向量，特征向量的作用主要有两个： 降低数据维度：通过提取特征向量，把原始数据的维度大大较低，简化模型的参数数量 提升模型性能：一个好的特征，可以提前把原始数据最关键的部分提取出来，因此可以提高学习机的性能 用于模型训练的每一个具体输入实例通常由特征向量表示，人工拆解特征的方法即所谓的特征工程，而深度学习算法自动将概念拆解成特征向量，免去的传统机器算法拆解特征这个步骤 ","date":"2020-01-28","objectID":"/ml/:3:0","series":null,"tags":["人工智能","机器学习"],"title":"机器学习初体验","uri":"/ml/#特征"},{"categories":["深度学习"],"content":"机器学习基本分类 ","date":"2020-01-28","objectID":"/ml/:0:0","series":null,"tags":["人工智能","机器学习"],"title":"机器学习初体验","uri":"/ml/#机器学习基本分类"},{"categories":["深度学习"],"content":"监督学习 监督学习是指从带有标注的训练数据中学习预测模型的机器学习问题。标注数据表示输入输出的对应关系，预测模型对给定的输入产生相应的输出。其本质是学习输入到输出映射的统计规律。 通常分为学习和预测两个过程，学习系统利用给定的训练数据集通过学习（或者说训练）得到一个模型，预测系统对给定的测试样本集的输入得出相应的输出。 问题分类： 输入变量 $X$ 和输出变量 $Y$有不同的类型，可以是连续的，也可以是离散的。根据输入输出的不同类型，对预测任务给予了不同的名称： 分类问题：输出变量为有限个离散变量 回归问题：输入变量与输出变量均为连续 标注问题：输入变量与输出变量均为变量序列 ","date":"2020-01-28","objectID":"/ml/:1:0","series":null,"tags":["人工智能","机器学习"],"title":"机器学习初体验","uri":"/ml/#监督学习"},{"categories":["深度学习"],"content":"非监督学习 非监督学习算法或者说无监督算法与监督学习算法的区别就在于，训练数据中只有输入是已知的，但是并没有为算法提供预期输出。需要算法自行总结数据中的规律，做出符合预期的判断。所以这类算法的理解和评估确实往往比较困难。 非监督学习算法可用于对已有数据的分析，也可以用于对未来数据的预测，与监督学习类似由学习系统和预测系统完成，其本质是学习数据中的统计规律或潜在结构。 非监督学习的两类算法： 聚类算法：根据数据的“相似性”将数据分为多类的过程，将数据集分成一个个的簇cluster（也可以理解为一组一组的形式） 降维算法：即在保证数据所具有的代表性特性或者分布的情况下，将高维数据转化为低维数据的过程（数据的可视化和精简数据） 非监督算法实例： 一家广告平台需要根据相似的人口学特征和购买习惯将美国人口分成不同的小组，以便广告客户可以通过有关联的广告接触到他们的目标客户 Airbnb 需要将自己的房屋清单分组成不同的社区，以便用户能更轻松地查阅这些清单 一个数据科学团队需要降低一个大型数据集的维度的数量，以便简化建模和降低文件大小 ","date":"2020-01-28","objectID":"/ml/:2:0","series":null,"tags":["人工智能","机器学习"],"title":"机器学习初体验","uri":"/ml/#非监督学习"},{"categories":["深度学习"],"content":"强化学习 强化学习指智能系统在与环境互动中学习最优行为策略的机器学习问题，本质是学习最优的序贯决策。学习过程中，系统不断的试错，已达到学习最优策略的目的。 大名鼎鼎的AlphaGo背后就有这强化学习算法的支持。 ","date":"2020-01-28","objectID":"/ml/:3:0","series":null,"tags":["人工智能","机器学习"],"title":"机器学习初体验","uri":"/ml/#强化学习"},{"categories":["深度学习"],"content":"半监督学习和自动学习 半监督学习：指利用标注数据和未标注数据学习，通常少量标注数据，大量未标注数据。因为标注数据的构建往往需要大量的人工，成本较高，未标注数据的收集则不需要太多成本。旨在利用未标注数据中的信息，辅助标注数据，进行监督学习，以较低的成本达到较好的学习效果 自动学习：指机器不断主动给出实例让教师进行标注，然后利用标注数据学习预测模型的机器学习问题。通常的监督学习使用给定的标注数据往往是随机得到的，可以看做是”被动学习“，主动学习的目标是找出对学习最有帮助的实例让教师标注，以较小的标注代价，达到更好的学习效果 半监督学习和主动学习更接近监督学习 ","date":"2020-01-28","objectID":"/ml/:4:0","series":null,"tags":["人工智能","机器学习"],"title":"机器学习初体验","uri":"/ml/#半监督学习和自动学习"},{"categories":["深度学习"],"content":"机器学习算法三要素 ","date":"2020-01-28","objectID":"/ml/:0:0","series":null,"tags":["人工智能","机器学习"],"title":"机器学习初体验","uri":"/ml/#机器学习算法三要素"},{"categories":["深度学习"],"content":"模型 模型是机器学习的最终结果，即上面所说的决策函数 $y=f(x)$ 或条件概率分布 $P(Y|X)$，它被用来预测特定问题下的某个输入对应的输出结果。而所有可能的决策函数或条件概率分布的集合便称为假设空间 ","date":"2020-01-28","objectID":"/ml/:1:0","series":null,"tags":["人工智能","机器学习"],"title":"机器学习初体验","uri":"/ml/#模型"},{"categories":["深度学习"],"content":"策略 有了模型的假设空间，机器学习接着需要考虑按照什么样的准则学习或选择最优的模型。机器学习的目标便是从假设空间中选取最优模型。而最优的定义则由我们所选则的评价准则定义的，即我们选取的模型的策略。通常评价模型在某个样本点的好坏用损失函数 $L(Y, f(X))$ 表示，而对所有样本预测的平均好坏用风险函数 $R_{exp}(f) = E[L(Y, f(X))]$ 表示 ","date":"2020-01-28","objectID":"/ml/:2:0","series":null,"tags":["人工智能","机器学习"],"title":"机器学习初体验","uri":"/ml/#策略"},{"categories":["深度学习"],"content":"算法 算法指学习模型的具体计算方法。机器学习基于训练数据集，根据学校策略，从假设空间中选择最优模型，最后需要考虑用什么样的计算方法求解最优模型 这时，机器学习问题归结为最优化问题，机器学习的算法成为求解最优化问题的算法。例如，当已经知道问题模型属于权值向量参数未定的线性决策函数，那么确定一个经验风险最小化的权值向量的过程就是这次学习的算法 机器学习方法之间的不同，主要来自其模型、策略、算法的不同。确定了模型、策略、算法，机器学习的方法也就确定了。这就是将其称为机器学习方法三要素的原因 ","date":"2020-01-28","objectID":"/ml/:3:0","series":null,"tags":["人工智能","机器学习"],"title":"机器学习初体验","uri":"/ml/#算法"},{"categories":["深度学习"],"content":"深度学习(Deep Learning) 讲深度学习前先讲讲神经网络，传统神经网络也是机器学习算法中的一员。而深度学习涉及训练多层神经网络，也称为深度神经网络。 未完待续… ","date":"2020-01-28","objectID":"/ml/:0:0","series":null,"tags":["人工智能","机器学习"],"title":"机器学习初体验","uri":"/ml/#深度学习deep-learning"}]